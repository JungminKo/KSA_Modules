{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'l': 2, 'h': 1, 'e': 1, 'o': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "s = 'hello'\n",
    "hello = Counter(s)\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x1,x2,x3,x4,x5 = to_categorical([0,1,2,2,3]).reshape(5,4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((x1,x2,x3,x4,x5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karpathy 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data I/O\n",
    "# data = open('no_such_thing.txt', 'r').read()\n",
    "# data = ' '.join(data.split('\\n'))\n",
    "# data = ''.join(data.split('\"'))\n",
    "# chars = list(set(data.lower()))\n",
    "# data_size, vocab_size = len(data), len(chars)\n",
    "# print('data has {} characters, {} uniques'.format(data_size, vocab_size))\n",
    "# char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "# ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "hidden_size = 3 # size of hiddne layer of neurons\n",
    "# seq_length = 25 # number of steps to unroll the RNN for\n",
    "# learing_rate = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4), (3, 3), (4, 3), (3, 1), (4, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(x1) # length of one-hot encoding vector\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "Wxh.shape, Whh.shape, Why.shape, bh.shape, by.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_t=\\text{tanh}(W_{hh}h_{t-1}+W_{xh}x_t)$$\n",
    "$$y_t=W_{hy}h_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]] \n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]] \n",
      "\n",
      " [[1. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [2. 2. 2.]\n",
      " [3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "Whh = np.ones((3,3))\n",
    "Wxh = np.ones((3,4))\n",
    "Why = np.tile(np.array([1,0,2,3], dtype=np.float32).reshape(-1,1), 3)\n",
    "print(Whh, '\\n\\n', Wxh, '\\n\\n', Why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76159416]\n",
      " [0.76159416]\n",
      " [0.76159416]] \n",
      "\n",
      " [[2.28478247]\n",
      " [0.        ]\n",
      " [4.56956494]\n",
      " [6.8543474 ]]\n"
     ]
    }
   ],
   "source": [
    "# h0 = np.zeros((hidden_size, 1)) # reset RNN Memory\n",
    "h1 = np.tanh(np.dot(Whh, h0) + np.dot(Wxh, x1) + bh)\n",
    "y1 = np.dot(Why, h1) + by\n",
    "print(h1, '\\n\\n', y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00930861],\n",
       "       [0.00094758],\n",
       "       [0.09144356],\n",
       "       [0.89830026]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.exp(y1) / np.sum(np.exp(y1))\n",
    "ix = np.random.choice(list(range(vocab_size)), p=p.ravel()) # 결과값에서 어떤 것을 선택할지는 프로그래머의 마음\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 2 # index 2가 9%의 확률로 뽑혔다고 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((vocab_size, 1))\n",
    "x[ix] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99719911]\n",
      " [0.99719911]\n",
      " [0.99719911]] \n",
      "\n",
      " [[2.99159734]\n",
      " [0.        ]\n",
      " [5.98319468]\n",
      " [8.97479202]]\n"
     ]
    }
   ],
   "source": [
    "h2 = np.tanh(np.dot(Whh, h1) + np.dot(Wxh, x) + bh)\n",
    "y2 = np.dot(Why, h2) + by\n",
    "print(h2, '\\n\\n', y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.39421535e-03],\n",
       "        [1.20206788e-04],\n",
       "        [4.76867174e-02],\n",
       "        [9.49798861e-01]]), 3)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.exp(y2) / np.sum(np.exp(y2))\n",
    "ix = np.random.choice(list(range(vocab_size)), p=p.ravel()) # 결과값에서 어떤 것을 선택할지는 프로그래머의 마음\n",
    "p, ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((vocab_size, 1))\n",
    "x[ix] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99931794]\n",
      " [0.99931794]\n",
      " [0.99931794]] \n",
      "\n",
      " [[2.99795381]\n",
      " [0.        ]\n",
      " [5.99590762]\n",
      " [8.99386143]]\n"
     ]
    }
   ],
   "source": [
    "h3 = np.tanh(np.dot(Whh, h2) + np.dot(Wxh, x) + bh)\n",
    "y3 = np.dot(Why, h3) + by\n",
    "print(h3, '\\n\\n', y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2.36476191e-03],\n",
       "        [1.17975717e-04],\n",
       "        [4.74004231e-02],\n",
       "        [9.50116839e-01]]), 3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.exp(y3) / np.sum(np.exp(y3))\n",
    "ix = np.random.choice(list(range(vocab_size)), p=p.ravel()) # 결과값에서 어떤 것을 선택할지는 프로그래머의 마음\n",
    "p, ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((vocab_size, 1))\n",
    "x[ix] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99932655]\n",
      " [0.99932655]\n",
      " [0.99932655]] \n",
      "\n",
      " [[2.99797965]\n",
      " [0.        ]\n",
      " [5.9959593 ]\n",
      " [8.99393895]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.36464291e-03],\n",
       "        [1.17966732e-04],\n",
       "        [4.73992626e-02],\n",
       "        [9.50118128e-01]]), 3)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4 = np.tanh(np.dot(Whh, h3) + np.dot(Wxh, x) + bh)\n",
    "y4 = np.dot(Why, h4) + by\n",
    "print(h4, '\\n\\n', y4)\n",
    "p = np.exp(y4) / np.sum(np.exp(y4))\n",
    "ix = np.random.choice(list(range(vocab_size)), p=p.ravel()) # 결과값에서 어떤 것을 선택할지는 프로그래머의 마음\n",
    "p, ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((vocab_size, 1))\n",
    "x[ix] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 뽑힌 단어는 hlooo\n",
    "- 제대로 학습시킨다면 hello를 출력시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_t=\\text{tanh}(W_{hh}h_{t-1}+W_{xh}x_t+b_h)$$\n",
    "$$y_t=W_{hy}h_t+b_y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://gist.github.com/karpathy/d4dee566867f8291f086"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(h, seed_ix, n):\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[seed_ix] = 1\n",
    "    ixes = []\n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(Whh, h) + np.dot(Wxh, x) + bh)\n",
    "        y = np.dot(Why, h) + by\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        ix = np.random.choice(list(range(vocab_size)), p=p.ravel())\n",
    "        x = np.zeros((vocab_size, 1))\n",
    "        x[ix] = 1\n",
    "        ixes.append(ix)\n",
    "    return ixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "[char_to_ix[ch] for ch in data.lower()[0:10]] # inputs\n",
    "[char_to_ix[ch] for ch in data.lower()[0+1:10+1]] # targets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13809978, 0.31157585, 0.55032436])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 / (1 + np.exp(np.array([2.,1.,.1])))) / np.sum(1 / (1 + np.exp(np.array([2.,1.,.1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\text{tanh}(x)$의 미분\n",
    "$$\\dfrac{d}{dx}\\text{tanh}(x)=1-\\text{tanh}^2(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFun(inputs, targets, hprev):\n",
    "    xs, hs, ys, ps = {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev)\n",
    "    loss = 0\n",
    "    # forward pass\n",
    "    for t in range(len(inputs)):\n",
    "        xs[t] = np.zeros((vocab_size, 1)) # encode in 1-of-k representation\n",
    "        xs[t][inputs[t]] = 1\n",
    "        hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden layer\n",
    "        ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "        ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "        loss += -np.log(ps[t][targets[t], 0]) # softmax (cross-entropy Loss)\n",
    "    # backward pass : compute gradients going backwards\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext = np.zeros_like(hs[0])\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        dy = np.copy(ps[t])\n",
    "        dy[targets[t]] -= -1 # backprop into y\n",
    "                             # see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
    "        dWhy += np.dot(dy, hs[t].T) # (vocab_size, 1) x (hidden_size, 1).T = (vocab_size, hidden_size)\n",
    "        dby += dy # add prop => 그대로\n",
    "        dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "                                        # (vocab_size, hidden_size).T x (vocab_size, 1) + (hidden_size, 1)\n",
    "                                        # 거꾸로 실행되기 대문에 h_t의 경우 역전파가 남아있음. dhnext를 더해준다.\n",
    "        dhraw = (1 - hs[t] * hs[t]) * dh # (hidden_size, 1)\n",
    "                                         # backprop through tanh nonlinearity\n",
    "        dbh += dhraw # add prop => 그대로\n",
    "        dWxh += np.dot(dhraw, xs[t].T) # (hidden_size, 1) x (vocab_size, 1).T\n",
    "        dWhh += np.dot(dhraw, hs[t].T) # (hidden_size, 1) x (hidden_size, 1).T\n",
    "        dhnext = np.dot(Whh.T, dhraw) # (hidden_size, hidden_size).T x (hidden_size, 1)\n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        np.clip(dparam, -5, 5, out=dparams) # clip to mitigate exploding gradients\n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.clip`\n",
    "- https://rfriend.tistory.com/tag/np.clip%28%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[2 2 2 3 4 5 6 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10) # Clip (limit) the values in an array.\n",
    "np.clip(a, 2, 7)\n",
    "print(a)\n",
    "np.clip(a, 2, 7, out=a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vanilla RNN에서 Vanishing Gradient 문제를 어떻게 해결할 것인가?\n",
    "- 200글자의 backprop을 모두 구한다면 상당한 어려움이 존재할 것\n",
    "- 이를 위해 분리된 Backprop (Truncated Backpropagation Through Time - BPTT)를 사용\n",
    "    - sequence length로 정해 놓은 변수 길이에 맞춰서 자르고\n",
    "    - 다음 step에서는 또 sequence length만큼 잘라서 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
