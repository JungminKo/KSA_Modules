{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. 크롤링과 스크레핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# adjust 한글 font\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "# plt.rcParams['font.family'] = 'NanumBarunGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1. Crawling & Scraping\n",
    "- 근래에는 정형화된 데이터보다 비정형 자료들을 많이 분석함\n",
    "- Social Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빅데이터의 수집\n",
    ">### 빅데이터\n",
    "- 대규모의 데이터 셋 (정의의 일부)\n",
    "- 데이터 수집만으로 의미 X, 데이터를 활용했을 때 가치 부여\n",
    "- 기존의 Data warehouse는 정형화되어있는 자료들을 다룸 (ex) 표\n",
    "    - 빅데이터는 정형화 이외의 자료도 분석의 대상으로 봄\n",
    "- 빅데이터의 Definition은 가지가지\n",
    "    - IBM 3V\n",
    "        - 크기 (Value)\n",
    "        - 속도 (Velocity)\n",
    "        - 다양성 (Variety)\n",
    "- 실시간으로 생성되는 자료\n",
    "    - 블로그와 SNS를 이용한 트렌드 분석\n",
    "    - 인터넷 전자상거래 상품 DB 분석\n",
    "    - 금융 정보를 이용한 예측\n",
    "    - 공공데이터를 이용한 인구, 미세먼지 등 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 스크레핑(Scaping)\n",
    "- _웹 사이트의 특정 정보를 추출하는 기술_\n",
    "- 공개된 정보는 대부분 HTML 형식으로 되어있어 필요한 데이터로 저장하기 위해 가공이 필요\n",
    "- 이를 위해 데이터 주고를 파악하는 것이 필요\n",
    "- 최근에는 로그인을 통해서만 유용한 정보에 접근할 수 있는 경우가 많다.\n",
    "    - 로그인 이후 필요한 웹 페이지 접근 기술이 필요\n",
    "- JS, 서버용 언어(PHP, ASP)가 중간에 끼기 때문에 접근이 어려울 수 있음\n",
    "\n",
    ">### 크롤링(Crawling)\n",
    "- _웹 사이트를 프로그램이 정기적으로 정보를 추출하는 기술_\n",
    "    - 크롤링하는 프로그램을 크롤러(crawler) 또는 스파이더(spider)\n",
    "\n",
    ">### 머신러닝에 사용할 수 있는 데이터 구조\n",
    "- 머신러닝뿐만 아니라 일반적인 분석에도 마찬가지, 수집한 자료를 편집하는 과정은 필수\n",
    "- 수집된 자료는 데이터의 구조를 분석하고 필요한 부분만 추출하여 분석 과정을 통해 머신러닝에 사용 가능\n",
    "- 데이터 형식은 파일 또는 DB에 저장하여 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Web component : HTML, HTTP\n",
    "\n",
    ">>### HTML\n",
    "- 프로그램 언어임 (물론 일반적인 언어와는 다름)\n",
    "- 태그(tag)는 꺾쇠 괄호 <>로 둘러싸여 있고, 그 안에 정보에 대한 의미를 작성\n",
    "- 그 의미가 끝나는 부분에 슬래시(/)를 사용하여 해당 태그를 종료\n",
    "        <title>Hello, World</title>       # 제목 요소, 값은 Hello, World\n",
    "        <img src=\"http://tcpschool.com/lectures/img_webbasic_10.png\" width=\"600\" height=\"300\"> # 맨 아래의 이미지 태그\n",
    "        \n",
    ">>### HTTP\n",
    "- HTTP(Hypertext Transaction Protocol)은 인터넷에서 컴퓨터 간에 정보를 주고받을 때 사용하는 일종의 약속\n",
    "- CS(Computer Science)에서 일반적으로 약속을 Protocol이라고 함\n",
    "\n",
    ">### 웹의 동작 순서\n",
    "- 웹 브라우저 실행 $\\rightarrow$ 주소 정보 입력\n",
    "- 주소 정보의 공식 이름은 **URL(Uniform Resource Locator)**\n",
    "- 출처 : https://joshua1988.github.io/web-development/http-part1/\n",
    "![title](https://joshua1988.github.io/images/posts/web/http/url-structure.png)\n",
    "- URL에는 해당 서버가 위치한 인터넷 주소 정보인 Domain Name이 존재\n",
    "- 흔히 도메인 정보 또는 서버 주소라고도 하는 이 주소를 통해 웹의 정보를 제공하는 서버에 접속\n",
    "- 일반적으로 컴퓨터는 **인터넷 프로토콜 주소(Internet Protocol Address)**, 즉 IP 주소라고 부르는 주소 값을 가짐\n",
    "    - IP 주소는 숫자로 되어있음. 이를 외우기는 쉽지 않음\n",
    "    - 보통 4가지 숫자를 이용하여 구성\n",
    "    - 즉, 외우기 쉽게 문자로 바꾼, domain name, URL을 사용함\n",
    "- IP 주소를 컴퓨터의 주소로 생각하면 이 주소에 접속하기 위해 사용하는 도메인 네임과 연결하기 위한 도메인 네임 서버(Domain Name Server, DNS)를 운영\n",
    "- 출처 : http://tcpschool.com/webbasic/works\n",
    "<img src=\"http://tcpschool.com/lectures/img_webbasic_10.png\" width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 다운로드 하기\n",
    ">### 웹상의 정보를 추출하는 방법\n",
    "- 웹 사이트의 텍스트를 가져오기 위해 프로그램적으로는 **Source**를 파악해야 한다.\n",
    "    - 즉, 최초에 source 분석을 해야한다.\n",
    "- 웹 사이트에 있는 데이터 추출을 위해 `urllib` 라이브러리 사용\n",
    "    - HTTP 또는 FTP(파일을 주고 받을 수 있는 protocol)를 이용해 데이터를 다운로드\n",
    "- `urllib`는 URL을 다루는 모듈을 모아놓은 패키지\n",
    "    - 특히 `urllib.request` 모듈은 웹 사이트에 있는 데이터에 접근하는 기능을 제공\n",
    "            urlertrieve(url, name)\n",
    "                - URL 주소의 파일을 다운로드\n",
    "            urlopen()\n",
    "                - 곧바로 파일을 저장하지 않고 메모리상에 load\n",
    "- 흔히 `a` 태그가 이동할 주소나 파일의 위치를 담고있음 (link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('test_download.png', <http.client.HTTPMessage at 0x2bb8d967208>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다운로드\n",
    "import urllib.request # 패키지 실행\n",
    "url = 'http://uta.pw/shodou/img/28/214.png' # 파일을 다운로드할 주소\n",
    "savename = 'test_download.png' # 저장할 파일 이름\n",
    "urllib.request.urlretrieve(url, savename) # 파일 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 상에 주소를 저장\n",
    "# 메모리 상에 load 후 바이너리 파일로 변환하여 파일을 저장\n",
    "url = 'http://uta.pw/shodou/img/28/214.png' # 파일을 다운로드할 주소\n",
    "savename = 'open_download.png' # 저장할 파일 이름\n",
    "# 파일 다운로드\n",
    "memory = urllib.request.urlopen(url).read() # URL 리소스를 열로 read 메소드 데이터 읽기\n",
    "# 파일로 저장\n",
    "with open(savename, 'wb') as f: # w 쓰기 모드, b 바이너리 모드\n",
    "    f.write(memory) # 메소드로 다운로드한 바이너리 데이터를 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gas_20180620.csv', <http.client.HTTPMessage at 0x2bba1233860>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공공데이터 포털\n",
    "url = 'https://www.data.go.kr/dataset/fileDownload.do?atchFileId=FILE_000000001455071&fileDetailSn=1&publicDataDetailPk=uddi:baa36625-7a28-4d54-b118-dc47ba14378c'\n",
    "savename = 'gas_20180620.csv'\n",
    "urllib.request.urlretrieve(url, savename) # 파일 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    절대주소 : http://www.exam.com/s/Ex.txt\n",
    "    상대주소 : s/Ex.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시군명</th>\n",
       "      <th>상호명</th>\n",
       "      <th>소재지</th>\n",
       "      <th>고압가스종류</th>\n",
       "      <th>데이터기준일자</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가평군</td>\n",
       "      <td>(재)예수의꽃동네유지재단 노체리안드리아자애병원</td>\n",
       "      <td>경기도 가평군 조종면 운악리</td>\n",
       "      <td>산소</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가평군</td>\n",
       "      <td>(주)팜스코</td>\n",
       "      <td>경기도 가평군 설악면 송산리</td>\n",
       "      <td>액화천연가스</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가평군</td>\n",
       "      <td>GS칼텍스청평연구소</td>\n",
       "      <td>경기도 가평군 설악면 사룡리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가평군</td>\n",
       "      <td>㈜꿈의동산</td>\n",
       "      <td>경기도 가평군 청평면 상천리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가평군</td>\n",
       "      <td>㈜협신</td>\n",
       "      <td>경기도 가평군 상면 봉수리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>가평군</td>\n",
       "      <td>대교디앤에스마이다스밸리골프클럽</td>\n",
       "      <td>경기도 가평군 설악면 이천리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>가평군</td>\n",
       "      <td>세계평화통일가정연합(박물관)</td>\n",
       "      <td>경기도 가평군 설악면 송산리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>가평군</td>\n",
       "      <td>아난티C.C서울클럽하우스</td>\n",
       "      <td>경기도 가평군 설악면 방일리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>가평군</td>\n",
       "      <td>아난티서울펜트하우스</td>\n",
       "      <td>경기도 가평군 설악면 방일리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>가평군</td>\n",
       "      <td>천주청평수련원</td>\n",
       "      <td>경기도 가평군 설악면 송산리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>가평군</td>\n",
       "      <td>청심신학대학원대학교(청심중고)</td>\n",
       "      <td>경기도 가평군 설악면 송산리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>가평군</td>\n",
       "      <td>청심어린이집</td>\n",
       "      <td>경기도 가평군 설악면 송산리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>가평군</td>\n",
       "      <td>청평수상스포츠빌라1구역</td>\n",
       "      <td>경기도 가평군 설악면 회곡리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>가평군</td>\n",
       "      <td>청평수상스포츠빌라2구역</td>\n",
       "      <td>경기도 가평군 설악면 회곡리</td>\n",
       "      <td>LPG</td>\n",
       "      <td>2018-06-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    시군명                        상호명              소재지  고압가스종류     데이터기준일자\n",
       "0   가평군  (재)예수의꽃동네유지재단 노체리안드리아자애병원  경기도 가평군 조종면 운악리      산소  2018-06-20\n",
       "1   가평군                     (주)팜스코  경기도 가평군 설악면 송산리  액화천연가스  2018-06-20\n",
       "2   가평군                 GS칼텍스청평연구소  경기도 가평군 설악면 사룡리     LPG  2018-06-20\n",
       "3   가평군                      ㈜꿈의동산  경기도 가평군 청평면 상천리     LPG  2018-06-20\n",
       "4   가평군                        ㈜협신   경기도 가평군 상면 봉수리     LPG  2018-06-20\n",
       "5   가평군           대교디앤에스마이다스밸리골프클럽  경기도 가평군 설악면 이천리     LPG  2018-06-20\n",
       "6   가평군            세계평화통일가정연합(박물관)  경기도 가평군 설악면 송산리     LPG  2018-06-20\n",
       "7   가평군              아난티C.C서울클럽하우스  경기도 가평군 설악면 방일리     LPG  2018-06-20\n",
       "8   가평군                 아난티서울펜트하우스  경기도 가평군 설악면 방일리     LPG  2018-06-20\n",
       "9   가평군                    천주청평수련원  경기도 가평군 설악면 송산리     LPG  2018-06-20\n",
       "10  가평군           청심신학대학원대학교(청심중고)  경기도 가평군 설악면 송산리     LPG  2018-06-20\n",
       "11  가평군                     청심어린이집  경기도 가평군 설악면 송산리     LPG  2018-06-20\n",
       "12  가평군               청평수상스포츠빌라1구역  경기도 가평군 설악면 회곡리     LPG  2018-06-20\n",
       "13  가평군               청평수상스포츠빌라2구역  경기도 가평군 설악면 회곡리     LPG  2018-06-20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas = pd.read_csv(savename, encoding='cp949')\n",
    "gas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 웹에서 데이터 추출하기\n",
    "- 웹에서 XML 또는 HTML 등의 텍스트 기반 데이터를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[ip]\\nAPI_URI=http://api.aoikujira.com/ip/get.php\\nREMOTE_ADDR=115.88.249.138\\nREMOTE_HOST=115.88.249.138\\nREMOTE_PORT=54564\\nHTTP_HOST=api.aoikujira.com\\nHTTP_USER_AGENT=Python-urllib/3.6\\nHTTP_ACCEPT_LANGUAGE=\\nHTTP_ACCEPT_CHARSET=\\nSERVER_PORT=80\\nFORMAT=ini\\n\\n'\n",
      "\n",
      " [ip]\n",
      "API_URI=http://api.aoikujira.com/ip/get.php\n",
      "REMOTE_ADDR=115.88.249.138\n",
      "REMOTE_HOST=115.88.249.138\n",
      "REMOTE_PORT=54564\n",
      "HTTP_HOST=api.aoikujira.com\n",
      "HTTP_USER_AGENT=Python-urllib/3.6\n",
      "HTTP_ACCEPT_LANGUAGE=\n",
      "HTTP_ACCEPT_CHARSET=\n",
      "SERVER_PORT=80\n",
      "FORMAT=ini\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어 들이기\n",
    "url = 'http://api.aoikujira.com/ip/ini' # 데이터를 가져올 주소\n",
    "res = urllib.request.urlopen(url) # URL 리소스를 열기\n",
    "data = res.read() # 바이너리 데이터로 읽기\n",
    "print(data) # 바이너리로 출력\n",
    "\n",
    "# 바이너리를 문자열로 변환 (HTML 소스 불러오기)\n",
    "text = data.decode('utf-8') # decode aptjemfmf \n",
    "print('\\n', text) # 문자열로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <!DOCTYPE html>\n",
      "    <html>\n",
      "    <head>\n",
      "        <meta charset=\"utf-8\">\n",
      "        <title>웹크롤링 기본:  크롤링(crawling) 이해 및 기본 - 잔재미코딩</title>\n",
      "        <meta name='title' content='웹크롤링 기본:  크롤링(crawling) 이해 및 기본 - 잔재미코딩'>\n",
      "        <meta name=\"description\" content=\"잔재미코딩은 IT 교육 컨텐츠와 강의 전문 연구소입니다.\">\n",
      "        <meta name=\"keywords\" content='웹크롤링 기본, 크롤링(crawling) 이해 및 기본'>\n",
      "        <meta name=\"author\" content=\"Dave Lee\">\n",
      "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "        <link rel=\"shortcut icon\" href=\"style/images/favicon.png\">\n",
      "        <link href=\"style/css/bootstrap.css\" rel=\"stylesheet\">\n",
      "        <link href=\"style/css/settings.css\" rel=\"stylesheet\">\n",
      "        <link href=\"style/css/owl.carousel.css\" rel=\"stylesheet\">\n",
      "        <link href=\"style/js/google-code-prettify/prettify.css\" rel=\"stylesheet\">\n",
      "        <link href=\"style/js/fancybox/jquery.fancybox.css\" rel=\"stylesheet\" type=\"text/css\" media=\"all\" />\n",
      "        <link href=\"style/js/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.2\" rel=\"stylesheet\" type=\"text/css\" />\n",
      "        <link href=\"style.css\" rel=\"stylesheet\">\n",
      "        <link href=\"style/css/color/blue.css\" rel=\"stylesheet\">\n",
      "        <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,500,600,700,800,900' rel='stylesheet' type='text/css'>\n",
      "        <link href='https://fonts.googleapis.com/earlyaccess/nanumpenscript.css' rel='stylesheet' type='text/css' />\n",
      "        <link href=\"style/type/fontello.css\" rel=\"stylesheet\">\n",
      "        <link href=\"style/type/picons.css\" rel=\"stylesheet\">\n",
      "        <link href=\"style/type/budicons.css\" rel=\"stylesheet\">\n",
      "        <script src=\"https://code.jquery.com/jquery-3.2.1.min.js\" integrity=\"sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=\" crossorigin=\"anonymous\">\n",
      "        </script>\n",
      "        <script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/jquery.jssocials/1.4.0/jssocials.min.js\"></script>\n",
      "        <link type=\"text/css\" rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/jquery.jssocials/1.4.0/jssocials.css\" />\n",
      "        <link type=\"text/css\" rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/jquery.jssocials/1.4.0/jssocials-theme-flat.css\" />\n",
      "        <link type=\"text/css\" rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\" />\n",
      "        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->\n",
      "        <!--[if lt IE 9]>\n",
      "          <script src=\"style/js/html5shiv.js\"></script>\n",
      "          <script src=\"https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js\"></script>\n",
      "          <![endif]-->\n",
      "        <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML\"></script>\n",
      "        <!-- MathJax configuration -->\n",
      "        <script type=\"text/x-mathjax-config\">\n",
      "        MathJax.Hub.Config({\n",
      "            tex2jax: {\n",
      "                inlineMath: [ ['$','$'] ],\n",
      "                displayMath: [ ['$$','$$']],\n",
      "                processEscapes: true,\n",
      "                processEnvironments: true\n",
      "            },\n",
      "            // Center justify equations in code and markdown cells. Elsewhere\n",
      "            // we use CSS to left justify single line equations in code cells.\n",
      "            displayAlign: 'center',\n",
      "            \"HTML-CSS\": {\n",
      "                styles: {'.MathJax_Display': {\"margin\": 0}},\n",
      "                linebreaks: { automatic: true }\n",
      "            }\n",
      "        });\n",
      "        </script>\n",
      "    </head>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어 들이기\n",
    "url = 'http://fun-coding.org/crawl_basic2.html' # 데이터를 가져올 주소\n",
    "res = urllib.request.urlopen(url) # URL 리소스를 열기\n",
    "data = res.read() # 바이너리 데이터로 읽기\n",
    "\n",
    "# 바이너리를 문자열로 변환 (HTML 소스 불러오기)\n",
    "text = data.decode('utf-8') # decode aptjemfmf \n",
    "print(text.split('<body')[0]) # 문자열로 출력\n",
    "                              # Head만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 매개변수를 추가해 요청을 전송하는 방법\n",
    "- URL에 매개변수를 추가해 요청을 전손\n",
    "- 기상청 RSS 서비스\n",
    "    - http://www.weather.go.kr/weather/lifenindustry/service_rss.jsp\n",
    "    - http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp?stnld=108\n",
    "         - ? 다음의 stnld=108가 매개변수\n",
    "- URL 끝부분에 ?를 입력하고 \\<key\\>=\\<value\\> 형식으로 매개변수 입력\n",
    "- 여러 개의 매개 변수인 경우, &를 사용하여 구분\n",
    "    - https://www.data.go.kr/search/index.do?\n",
    "          query : (index=OPENAPI) & (query=%EA%B4%80%EA%B4%91) & (currentPage=3) & (countPerPage=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`urllib.parse.urlencode()`\n",
    "- 굉장히 중요\n",
    "- 한글을 parsing해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stnld=108\n",
      "url=http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp?stnld=108\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n",
      "<rss version=\"2.0\">\n",
      "<channel>\n",
      "<title>기상청 육상 중기예보</title>\n",
      "<link>http://www.kma.go.kr/weather/forecast/mid-term_01.jsp</link>\n",
      "<description>기상청 날씨 웹서비스</description>\n",
      "<language>ko</language>\n",
      "<generator>기상청</generator>\n",
      "<pubDate>2019년 07월 01일 (월)요일 06:00</pubDate>\n",
      " <item>\n",
      "<author>기상청</author>\n",
      "<category>육상중기예보</category>\n",
      "<title>전국 육상 중기예보 - 2019년 07월 01일 (월)요일 06:00 발표</title>\n",
      "<link>http://www.kma.go.kr/weather/forecast/mid-term_01.jsp</link>\n",
      "<guid>http://www.kma.go.kr/weather/forecast/mid-term_01.jsp</guid>\n",
      "<description>\n",
      "\t<header>\n",
      "\t\t<title>전국 육상중기예보</title>\n",
      "\t\t<tm>201907010600</tm>\n",
      "\t\t<wf><![CDATA[장마전선의 영향으로 6~7일에 남부지방과 제주도에 비가 오겠습니다.  <br />그 밖의 날은 고기압의 영향으로 맑은 날이 많겠습니다.<br />기온은 평년(최저기온: 18~22℃, 최고기온: 25~30℃) 보다 4~5일에는 조금 높겠고, 그 밖의 날은 비슷하겠습니다.<br />강수량은 평년(5~18mm)보다 남부지방과 제주도는 많겠고, 중부지방은 적겠습니다.<br /><br />* 한편, 장마전선은 6일부터 제주도남쪽먼바다에서 다시 북상할 것으로 예상되나, 북태평양고기압의 확장 정도에 따라 장마전선의 위치와 강수 영역이 달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.<br />* 내륙지역을 중심으로 낮 기온이 30도 이상 올라 덥겠으니, 보건, 축산 등 폭염피해에 유의하기 바랍니다.]]></wf>\n",
      "\t</header>\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "import urllib.request # 패키지 실행\n",
    "import urllib.parse # 패키지 실행\n",
    "# 데이터 읽기\n",
    "API = 'http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp' # 매개변수를 URL 인코딩\n",
    "# 매개변수(딕셔너리 자료형)을 URL 인코딩\n",
    "value = {'stnld' : '108'}\n",
    "params = urllib.parse.urlencode(value) # 매개변수를 URL 인코딩\n",
    "print(params)\n",
    "\n",
    "# 요청 URL 생성\n",
    "url = API + '?' + params # URL 리소스 열기\n",
    "print('url={0}'.format(url))\n",
    "\n",
    "# 다운로드\n",
    "res = urllib.request.urlopen(url) # URL 리소스 열기\n",
    "data = res.read() # 바이너리 데이터로 읽기\n",
    "\n",
    "# 바이너리를 문자열로 변환 (HTML 소스 불러오기)\n",
    "text = data.decode('utf-8')\n",
    "print(text.split('<body')[0]) # 문자열로 출력\n",
    "                              # Header만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 매개변수를 명령줄에서 지정하기\n",
    "- 앞선 프로그램에서는 매개변수를 코드에서 입력해야 하므로 다른 지역은 매개변수를 지정하려면 프로그램을 수정\n",
    "- 명령줄에서 바로 지역번호를 입력하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage : download-forecast-argv : 104\n",
      "Usage : download-forecast-argv : 105\n",
      "URL= http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnld=105\n",
      "Usage : download-forecast-argv : 159\n",
      "URL= http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnld=159\n",
      "Usage : download-forecast-argv : exit\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 호출\n",
    "import sys\n",
    "import urllib.request as req\n",
    "import urllib.parse as parse\n",
    "\n",
    "# 입력줄 매개변수 추출\n",
    "text = [] # 문서를 저장할 리스트 초기화\n",
    "while True:\n",
    "    # 입력줄을 이용하여 지역번호 입력\n",
    "    region_number = input('Usage : download-forecast-argv : ')\n",
    "    \n",
    "    # 반복구문 졸료 조건\n",
    "    if region_number.upper() == 'EXIT':\n",
    "        break\n",
    "    elif int(region_number) not in [108, 109, 105, 131, 133, 146, 156, 134, 159, 184]:\n",
    "        continue\n",
    "    \n",
    "    # 매개변수를 URL 인코딩(한글을 포함하는 경우 필수로 실행)\n",
    "    API = 'http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'\n",
    "    \n",
    "    values = {'stnld' : region_number}\n",
    "    params = parse.urlencode(values)\n",
    "    url = API + '?' + params\n",
    "    print('URL=', url)\n",
    "    \n",
    "    # 페이지 다운로드\n",
    "    data = req.urlopen(url).read()\n",
    "    text.append(data.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup으로 scraping하기\n",
    ">### BeautifulSoup으로 scraping\n",
    "- 스크레핑이란 웹 사이트에서 데이터를 추출하여 원하는 정보를 얻어내는 것\n",
    "- 파이썬에서 스크레핑할 때 빼놓을 수 없는 라이브러리, BeautifulSoup\n",
    "        pip install beautifulsoup4\n",
    "    - BeautifulSoup을 HTML과 XML에서 정보 추출이 가능\n",
    "    - HTML과 XML 분석을 해주는 라이브러리\n",
    "    - 자체로 다운로드 기능은 없음\n",
    "- HTML 구조로 요소를 추출 `BeautifulSoup()` 함수 사용\n",
    "    - HTML 구조로 요소를 추출하는 것, HTML 구조를 하나하나 적어나가는 것은 매우 복잡\n",
    "    - 간단하게 요소를 찾아내는 방법이 필요\n",
    "        <table>\n",
    "          <thead>\n",
    "            <tr>\n",
    "              <th>markup parser</th>\n",
    "              <th>설명</th>\n",
    "            </tr>\n",
    "          </thead>\n",
    "          <tbody>\n",
    "            <tr>\n",
    "              <td><code class=\"highlighter-rouge\">html.parser</code></td>\n",
    "              <td>기본옵션으로 빠르지만 유연하지 못함 (단순하 html 문서에서 사용)</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "              <td><code class=\"highlighter-rouge\">lxml</code></td>\n",
    "              <td>매우 빠르고 유연</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "              <td><code class=\"highlighter-rouge\">xml</code></td>\n",
    "              <td>XML 파일에만 사용</td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "              <td><code class=\"highlighter-rouge\">html5lib</code></td>\n",
    "              <td>매우 느리지만 유연 (구조가 복잡한 HTML 문서에 사용)</td>\n",
    "            </tr>\n",
    "          </tbody>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html><body>\n",
      "<h1>스크레핑이란?</h1>\n",
      "<p>웹 페이지를 분석하는 것</p>\n",
      "<p>원하는 부분을 추출하는 것</p>\n",
      "</body></html>\n",
      " \n",
      "\n",
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   스크레핑이란?\n",
      "  </h1>\n",
      "  <p>\n",
      "   웹 페이지를 분석하는 것\n",
      "  </p>\n",
      "  <p>\n",
      "   원하는 부분을 추출하는 것\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      " \n",
      "\n",
      "<p>웹 페이지를 분석하는 것</p>\n",
      "\n",
      "\n",
      "<p>원하는 부분을 추출하는 것</p>\n",
      "h1 = 스크레핑이란?\n",
      "p1 = 웹 페이지를 분석하는 것\n",
      "p2 = 원하는 부분을 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 호출\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 분석할 HTML\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<h1>스크레핑이란?</h1>\n",
    "<p>웹 페이지를 분석하는 것</p>\n",
    "<p>원하는 부분을 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "# HTML 분석하기\n",
    "soup = BeautifulSoup(html, 'html.parser') # BeautifulSoup 객체 생성\n",
    "print(soup, '\\n')\n",
    "print(soup.prettify(), '\\n')\n",
    "\n",
    "# 원하는 부분 추출\n",
    "h1 = soup.html.body.h1 # HTML 태그 구조를 이용하여 접근\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling # nest_sibling 첫 번째 p태그 다음 공백 줄바꿈 문자\n",
    "                                  # next_sibling 두 번째 p태그\n",
    "print(p1) # p1 tag\n",
    "print(p1.next_sibling) # \\n\n",
    "print(p1.next_sibling.next_sibling) # p2 tag\n",
    "\n",
    "# 요소의 글자 출력\n",
    "print('h1 = {0}'.format(h1.string))\n",
    "print('p1 = {0}'.format(p1.string))\n",
    "print('p2 = {0}'.format(p2.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<p>웹 페이지를 분석하는 것</p>, <p>웹 페이지를 분석하는 것</p>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1 = soup.body.p\n",
    "p1, P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body.p.previous_sibling # 줄바꿈 문자를 읽어와보리기~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### id로 요소를 찾는 방법\n",
    "- id 속성을 지정하여 요소를 찾는 `find()` 메서드를 제공\n",
    "        find(tag_name, attrs={}) 메서드를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML_Exam.html\n",
    "```\n",
    "﻿<!DOCTYPE html>\n",
    "<html>\n",
    "\t<head>\n",
    "\t\t<title>Page title</title>\n",
    "\t</head>\n",
    "\t<body>\n",
    "    \t<div>\n",
    "            <p>a</p>\n",
    "            <p>b</p>\n",
    "            <p>c</p>\n",
    "        </div>\n",
    "        <div class=\"ex_class\">\n",
    "            <p>d</p>\n",
    "            <p>e</p>\n",
    "            <p>f</p>\n",
    "        </div>\n",
    "        <div id=\"ex_id\">\n",
    "            <p>g</p>\n",
    "            <p>h</p>\n",
    "            <p>i</p>\n",
    "        </div>\n",
    "\t\t<h1>This is a heading</h1>\n",
    "\t\t<p>This is a paragraph.</p>\n",
    "\t\t<p>This is another paragraph.</p>\n",
    "\t</body>\n",
    "</html>\n",
    "```\n",
    "<html>\n",
    "\t<head>\n",
    "\t\t<title>Page title</title>\n",
    "\t</head>\n",
    "\t<body>\n",
    "    \t<div>\n",
    "            <p>a</p>\n",
    "            <p>b</p>\n",
    "            <p>c</p>\n",
    "        </div>\n",
    "        <div class=\"ex_class\">\n",
    "            <p>d</p>\n",
    "            <p>e</p>\n",
    "            <p>f</p>\n",
    "        </div>\n",
    "        <div id=\"ex_id\">\n",
    "            <p>g</p>\n",
    "            <p>h</p>\n",
    "            <p>i</p>\n",
    "        </div>\n",
    "\t\t<h1>This is a heading</h1>\n",
    "\t\t<p>This is a paragraph.</p>\n",
    "\t\t<p>This is another paragraph.</p>\n",
    "\t</body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** div 태그\n",
      "<div>\n",
      "<p>a</p>\n",
      "<p>b</p>\n",
      "<p>c</p>\n",
      "</div> \n",
      "\n",
      "*** div 태그, class=ex_class\n",
      "<div class=\"ex_class\">\n",
      "<p>d</p>\n",
      "<p>e</p>\n",
      "<p>f</p>\n",
      "</div> \n",
      "\n",
      "*** div 태그, id=ex_id\n",
      "<div id=\"ex_id\">\n",
      "<p>g</p>\n",
      "<p>h</p>\n",
      "<p>i</p>\n",
      "</div> \n",
      "\n",
      "*** p 태그\n",
      "<p>a</p>\n"
     ]
    }
   ],
   "source": [
    "# 파일 열기\n",
    "fp = open('C:/workspace/KSA\\data/modeule04/ch01/HTML_Exam.html', 'r',\n",
    "         encoding='utf-8')\n",
    "\n",
    "soup = BeautifulSoup(fp, 'html.parser') # BeautifulSoup 객체 생성\n",
    "divs = soup.find('div') # div 태그\n",
    "divs_class = soup.find('div', class_='ex_class') # div 태그, class\n",
    "divs_id = soup.find('div', id='ex_id') # div 태그, id\n",
    "p = soup.find('p') # p 태그\n",
    "print('*** div 태그\\n{0}'.format(divs), '\\n')\n",
    "print('*** div 태그, class=ex_class\\n{0}'.format(divs_class), '\\n')\n",
    "print('*** div 태그, id=ex_id\\n{0}'.format(divs_id), '\\n')\n",
    "print('*** p 태그\\n{0}'.format(p))\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<p>a</p>\n",
       "<p>b</p>\n",
       "<p>c</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\na\\nb\\nc\\n', None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divs.text, divs.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>c</p>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.next_sibling.next_sibling.next_sibling.next_sibling # div 태그 이하로는 내려가지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>h</p>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body.div.next_sibling.next_sibling.next_sibling.next_sibling.p.next_sibling.next_sibling # 너무 복잡한디...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- 여러 개의 요소 추출하기\n",
    "        find_all(tag_name, attrs={}) 메서드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** div 태그\n",
      "[<div>\n",
      "<p>a</p>\n",
      "<p>b</p>\n",
      "<p>c</p>\n",
      "</div>, <div class=\"ex_class\">\n",
      "<p>d</p>\n",
      "<p>e</p>\n",
      "<p>f</p>\n",
      "</div>, <div id=\"ex_id\">\n",
      "<p>g</p>\n",
      "<p>h</p>\n",
      "<p>i</p>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "# 파일 열기\n",
    "fp = open('C:/workspace/KSA\\data/modeule04/ch01/HTML_Exam.html', 'r',\n",
    "         encoding='utf-8')\n",
    "\n",
    "soup = BeautifulSoup(fp, 'html.parser') # BeautifulSoup 객체 생성\n",
    "divs = soup.find_all('div') # 모든 div 태그\n",
    "print('*** div 태그\\n{0}'.format(divs))\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- 온라인 파일 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** a 태그, class=\"ah_da\"\n",
      "[<a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EC%86%A1%EC%A4%91%EA%B8%B0+%ED%83%88%EB%AA%A8%EC%82%AC%EC%A7%84&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EB%B0%98%EB%A0%A4%EB%8F%99%EB%AC%BC+%EB%93%B1%EB%A1%9D&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EC%8B%9C%EB%AA%AC%EC%8A%A4+%EC%9B%A8%EB%94%A9+%ED%94%84%EB%A1%9C%EB%AA%A8%EC%85%98&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EC%9C%A0%ED%95%9C%EC%96%91%ED%96%89&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EA%B9%BB%EC%9E%8E%EB%8B%A4%EC%9D%B4%EC%96%B4%ED%8A%B8&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EC%A7%80%EC%98%A4%EC%8A%A4%ED%86%B0&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EB%94%94%EC%98%A4+%EC%86%94%EB%A1%9C&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EC%9E%A5%EC%8B%A0%EC%98%81&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%ED%96%89%EC%A3%BC%EC%82%B0%EC%84%B1+%EC%B2%A0%ED%8C%90%EA%B5%AC%EC%9D%B4&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EA%B9%80%EB%AF%B8%EB%A0%A4&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EB%94%94%EC%98%A4&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EB%B8%94%EB%9E%99%EC%97%85+%EC%8B%9C%EC%A6%8C%EC%98%A4%ED%94%84&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EA%B9%80%EC%88%98%ED%98%84&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%ED%96%84%EC%8A%A4%ED%84%B0%EC%99%80+%EA%B7%B8%EB%85%80&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EC%97%AC%EC%9E%90%EC%B9%9C%EA%B5%AC&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%ED%86%B0+%ED%99%80%EB%9E%9C%EB%93%9C&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EB%AF%BC%ED%9D%AC%EC%A7%84&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%ED%99%8D%EC%A3%BC&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EC%95%84%EB%A6%AC%EB%94%B0%EC%9B%80+%EB%8C%80%EB%9E%80&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>, <a class=\"ah_da\" data-clk=\"lve.kwdhistory\" href=\"http://datalab.naver.com/keyword/realtimeDetail.naver?datetime=2019-07-01T18:08:00&amp;query=%EB%8F%84%EA%B2%BD%EC%88%98&amp;where=main\">\n",
      "<span class=\"blind\">데이터랩 그래프 보기</span>\n",
      "<span class=\"ah_ico_datagraph\"></span>\n",
      "</a>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# 온라인 파일 열기\n",
    "url = urlopen('http://www.naver.com')\n",
    "soup = BeautifulSoup(url, 'html.parser')\n",
    "a = soup.find_all('a', class_='ah_da') # 모든 a 태그, class='ah_da'\n",
    "print('*** a 태그, class=\"ah_da\"\\n{0}'.format(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tag = soup.find_all('div', class_='api_atcmp_wrap _keywords', style=\"display:none;\")\n",
    "tag = soup.find_all('div', {'class':'api_atcmp_wrap _keywords', 'style':\"display:none;\"}) # dict로 넣을 땐 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "기상청 육상 중기예보\n",
      "wf<wf><![CDATA[장마전선의 영향으로 6~7일에 남부지방과 제주도에 비가 오겠습니다.  <br />그 밖의 날은 고기압의 영향으로 맑은 날이 많겠습니다.<br />기온은 평년(최저기온: 18~22℃, 최고기온: 25~30℃) 보다 4~5일에는 조금 높겠고, 그 밖의 날은 비슷하겠습니다.<br />강수량은 평년(5~18mm)보다 남부지방과 제주도는 많겠고, 중부지방은 적겠습니다.<br /><br />* 한편, 장마전선은 6일부터 제주도남쪽먼바다에서 다시 북상할 것으로 예상되나, 북태평양고기압의 확장 정도에 따라 장마전선의 위치와 강수 영역이 달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.<br />* 내륙지역을 중심으로 낮 기온이 30도 이상 올라 덥겠으니, 보건, 축산 등 폭염피해에 유의하기 바랍니다.]]></wf>\n"
     ]
    }
   ],
   "source": [
    "# 온라인 파일 열기\n",
    "url = urlopen('http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp')\n",
    "soup = BeautifulSoup(url, 'html.parser')\n",
    "title = soup.find('title').string # title tag\n",
    "wf = soup.find('wf') # wf 태그\n",
    "print('Title\\n{0}'.format(title))\n",
    "print('wf{0}'.format(wf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "기상청 육상 중기예보\n",
      "wf : 장마전선의 영향으로 6~7일에 남부지방과 제주도에 비가 오겠습니다.  <br />그 밖의 날은 고기압의 영향으로 맑은 날이 많겠습니다.<br />기온은 평년(최저기온: 18~22℃, 최고기온: 25~30℃) 보다 4~5일에는 조금 높겠고, 그 밖의 날은 비슷하겠습니다.<br />강수량은 평년(5~18mm)보다 남부지방과 제주도는 많겠고, 중부지방은 적겠습니다.<br /><br />* 한편, 장마전선은 6일부터 제주도남쪽먼바다에서 다시 북상할 것으로 예상되나, 북태평양고기압의 확장 정도에 따라 장마전선의 위치와 강수 영역이 달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.<br />* 내륙지역을 중심으로 낮 기온이 30도 이상 올라 덥겠으니, 보건, 축산 등 폭염피해에 유의하기 바랍니다.\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 구름많음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 구름많음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 구름많음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 구름많음\n",
      "wf : 맑음\n",
      "wf : 맑음\n",
      "wf : 맑음\n"
     ]
    }
   ],
   "source": [
    "# 온라인 파일 열기\n",
    "url = urlopen('http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp')\n",
    "soup = BeautifulSoup(url, 'html.parser')\n",
    "title = soup.find('title').string # title tag\n",
    "wf = soup.find_all('wf') # 모든 wf 태그\n",
    "print('Title\\n{0}'.format(title))\n",
    "for ix, x in enumerate(wf):\n",
    "    if ix > 40:\n",
    "        break\n",
    "    text = x.string # wf tag 하나의 문자열\n",
    "    print('wf : {0}'.format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CSS(Cascading Style Sheets) 선택자\n",
    "- CSS는 웹 문서의 전반적인 스타일을 미리 저장해 둔 스타일시트로 문서 전체의 일관성을 유지할 수 있고, 세세한 스타일 지정의 필요를 줄어들게 함\n",
    "- CSS 선택자를 지정해서 원하는 요소를 추출. `soup = bs4.BeautifulSoup(html, 'html.parser')` 일 때,\n",
    "    <table>\n",
    "      <thead>\n",
    "        <tr>\n",
    "          <th>메서드</th>\n",
    "          <th>설명</th>\n",
    "        </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\">soup.select_one(<선택자>)</code></td>\n",
    "          <td>CSS 선택자로 요소 하나를 추출</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\">soup.select(<선택자>)</code></td>\n",
    "          <td>CSS 선택자로 요소 여러 개를 리스트로 추출</td>\n",
    "        </tr>\n",
    "      </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSS_Exam.html\n",
    "```\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\" />\n",
    "    <meta name=\"keywords\" content=\"CSS, HTML\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "        <title>CSS 선택자</title>\n",
    "</head>\n",
    "<body>\n",
    "\t<div id=\"meigen\">\n",
    "\t\t<h1>파이썬 프로그램</h1>\n",
    "\t\t<ul class=\"items\">\n",
    "\t\t\t<li><a href=\"/Python/Basics\">Python 기초</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Gui\">GUI 프로그래밍</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Data\">Python 데이타</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Django\">Django 기초</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Applications\">Python 활용</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Tips\">Python 팁</a></li>\n",
    "\t\t\t<li><a href=\"/Home/Contact\">Contact</a></li>\n",
    "\t\t\t<li><a href=\"javascript:showSearch()\"><i class=\"fa fa-search\" aria-hidden=\"true\"></i>검색</a></li>\n",
    "\t\t</ul>\n",
    "\t</div>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\" />\n",
    "    <meta name=\"keywords\" content=\"CSS, HTML\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "        <title>CSS 선택자</title>\n",
    "</head>\n",
    "<body>\n",
    "\t<div id=\"meigen\">\n",
    "\t\t<h1>파이썬 프로그램</h1>\n",
    "\t\t<ul class=\"items\">\n",
    "\t\t\t<li><a href=\"/Python/Basics\">Python 기초</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Gui\">GUI 프로그래밍</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Data\">Python 데이타</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Django\">Django 기초</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Applications\">Python 활용</a></li>\n",
    "\t\t\t<li><a href=\"/Python/Tips\">Python 팁</a></li>\n",
    "\t\t\t<li><a href=\"/Home/Contact\">Contact</a></li>\n",
    "\t\t\t<li><a href=\"javascript:showSearch()\"><i class=\"fa fa-search\" aria-hidden=\"true\"></i>검색</a></li>\n",
    "\t\t</ul>\n",
    "\t</div>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1=파이썬 프로그램\n",
      "li_list =\n",
      "<li>\n",
      " <a href=\"/Python/Basics\">\n",
      "  Python 기초\n",
      " </a>\n",
      "</li>\n",
      "<li>\n",
      " <a href=\"/Python/Gui\">\n",
      "  GUI 프로그래밍\n",
      " </a>\n",
      "</li>\n",
      "<li>\n",
      " <a href=\"/Python/Data\">\n",
      "  Python 데이타\n",
      " </a>\n",
      "</li>\n",
      "<li>\n",
      " <a href=\"/Python/Django\">\n",
      "  Django 기초\n",
      " </a>\n",
      "</li>\n",
      "<li>\n",
      " <a href=\"/Python/Applications\">\n",
      "  Python 활용\n",
      " </a>\n",
      "</li>\n",
      "<li>\n",
      " <a href=\"/Python/Tips\">\n",
      "  Python 팁\n",
      " </a>\n",
      "</li>\n",
      "<li>\n",
      " <a href=\"/Home/Contact\">\n",
      "  Contact\n",
      " </a>\n",
      "</li>\n",
      "<li>\n",
      " <a href=\"javascript:showSearch()\">\n",
      "  <i aria-hidden=\"true\" class=\"fa fa-search\">\n",
      "  </i>\n",
      "  검색\n",
      " </a>\n",
      "</li>\n",
      "['Python 기초', 'GUI 프로그래밍', 'Python 데이타', 'Django 기초', 'Python 활용', 'Python 팁', 'Contact', None]\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 호출\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 파일 열기\n",
    "fp = open('C:/workspace/KSA\\data/modeule04/ch01/CSS_Exam.html', 'r',\n",
    "         encoding='utf-8')\n",
    "\n",
    "soup = BeautifulSoup(fp, 'html.parser') # BeautifulSoup 객체 생성\n",
    "\n",
    "# tag = soup.body.div.h1\n",
    "# tag = soup.find('div', id='meigen').h1 # 뭔가 요소가 많음!\n",
    "\n",
    "# CSS query로 추출하기\n",
    "# 제목 부분 추출하기\n",
    "\n",
    "h1 = soup.select_one('div#meigen > h1').string\n",
    "print('h1={0}'.format(h1))\n",
    "\n",
    "# 목록 부분 추출\n",
    "li_list = soup.select('div#meigen > ul.items > li') # '#'다음에는 id, '.'다음에는 class\n",
    "# li_list = soup.select('div#meigen > ul > li') # items 안넣어도 현재는 무방\n",
    "print('li_list =')\n",
    "for content in li_list:\n",
    "    print(content.prettify(), end='')\n",
    "\n",
    "print([i.string for i in li_list])\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li><a href=\"/Python/Basics\">Python 기초</a></li>,\n",
       " <li><a href=\"/Python/Gui\">GUI 프로그래밍</a></li>,\n",
       " <li><a href=\"/Python/Data\">Python 데이타</a></li>,\n",
       " <li><a href=\"/Python/Django\">Django 기초</a></li>,\n",
       " <li><a href=\"/Python/Applications\">Python 활용</a></li>,\n",
       " <li><a href=\"/Python/Tips\">Python 팁</a></li>,\n",
       " <li><a href=\"/Home/Contact\">Contact</a></li>,\n",
       " <li><a href=\"javascript:showSearch()\"><i aria-hidden=\"true\" class=\"fa fa-search\"></i>검색</a></li>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 네이버 금융에서 환율 정보 추출\n",
    "- https://finance.naver.com/marketindex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 환전 고시 환율 ***\n",
      "미국 USD=1,162.50\n",
      "\n",
      "미국 USD : 1,162.50\n",
      "일본 JPY(100엔) : 1,073.95\n",
      "유럽연합 EUR : 1,317.29\n",
      "중국 CNY : 169.83\n",
      "일본 엔/달러 : 107.8900\n",
      "달러/유로 : 1.1389\n",
      "달러/영국파운드 : 1.2695\n",
      "달러인덱스 : 95.6600\n",
      "WTI : 58.47\n",
      "휘발유 : 1496.64\n",
      "국제 금 : 1409.7\n",
      "국내 금 : 51905.16\n"
     ]
    }
   ],
   "source": [
    "url = urlopen('https://finance.naver.com/marketindex/')\n",
    "\n",
    "soup = BeautifulSoup(url, 'html.parser', from_encoding='cp949')\n",
    "h2 = soup.select_one('div.title > h2.h_market1 > span').string\n",
    "print('*** {0} ***'.format(h2))\n",
    "\n",
    "title = soup.select_one('h3.h_lst > span.blind').string\n",
    "val  = soup.select_one('div.head_info > span.value').string\n",
    "print('{0}={1}\\n'.format(title, val))\n",
    "\n",
    "title_list = soup.select('h3.h_lst > span.blind')\n",
    "val_list = soup.select('div.head_info > span.value')\n",
    "n = len(title_list)\n",
    "for i in range(0, n):\n",
    "    print('{0} : {1}'.format(title_list[i].string, \n",
    "                             val_list[i].string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유니코드\n",
    " - https://soooprmx.com/archives/4912\n",
    " - https://ourcstory.tistory.com/78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### CSS 선택자로 지정할 수 있는 서식\n",
    "- 기본서식\n",
    "    <table>\n",
    "      <thead>\n",
    "        <tr>\n",
    "          <th>서식</th>\n",
    "          <th>설명</th>\n",
    "        </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\">*</code></td>\n",
    "          <td>모든 요소 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소이름></code></td>\n",
    "          <td>요소 이름 기반으로 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\">.<클래스이름></code></td>\n",
    "          <td>클래스 이름 기반으로 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\">#&lt;id 이름&gt;</code></td>\n",
    "          <td>id 속성 기반으로 선택</td>\n",
    "        </tr>\n",
    "      </tbody>\n",
    "    </table>\n",
    "- 선택자들의 관계를 지정하는 서식\n",
    "    <table>\n",
    "      <thead>\n",
    "        <tr>\n",
    "          <th>서식</th>\n",
    "          <th>설명</th>\n",
    "        </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><선택자>, <선택자></code></td>\n",
    "          <td>쉼표로 구분된 여러 개의 선택자를 모두 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><선택자> <선택자></code></td>\n",
    "          <td>앞 선택자의 후손 중 뒤 선택자에 해당하는 것을 모두 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><선택자> > <선택자></code></td>\n",
    "          <td>앞 선택자의 자손 중 뒤 선택자에 해당하는 것을 모두 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><선택자> + <선택자></code></td>\n",
    "          <td>감은 계증에서 바로 뒤에 있는 요소를 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><선택자1> ~ <선택자2></code></td>\n",
    "          <td>선택자 1부터 선택자 2까지의 요소를 모두 선택</td>\n",
    "        </tr>\n",
    "      </tbody>\n",
    "    </table>\n",
    "- 선택자 속성을 기반으로 지정하는 서식\n",
    "    <table>\n",
    "      <thead>\n",
    "        <tr>\n",
    "          <th>서식</th>\n",
    "          <th>설명</th>\n",
    "        </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>[<속성>]</code></td>\n",
    "          <td>해당 속성을 가진 요소를 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>[<속성>=<값>]</code></td>\n",
    "          <td>해당 속성의 값이 지정한 값과 같은 요소를 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>[<속성>~=<값>]</code></td>\n",
    "          <td>해당 속성의 값이 지정한 값을 단어로 포함하고 있다면 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>[<속성>|=<값>]</code></td>\n",
    "          <td>해당 속성의 값으로 시작하면 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>[<속성>^=<값>]</code></td>\n",
    "          <td>해당 속성의 값이 지정한 값으로 시작하면 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>[<속성>$=<값>]</code></td>\n",
    "          <td>해당 속성의 값이 지정한 값으로 끝나면 선택</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>[<속성>*=<값>]</code></td>\n",
    "          <td>해당 속성의 값이 지정한 값을 포함하고 있다면 선택</td>\n",
    "        </tr>\n",
    "      </tbody>\n",
    "    </table>\n",
    "- 위치 또는 상태를 지정하는 서식\n",
    "    <table>\n",
    "      <thead>\n",
    "        <tr>\n",
    "          <th>서식</th>\n",
    "          <th>설명</th>\n",
    "        </tr>\n",
    "      </thead>\n",
    "      <tbody>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:root</code></td>\n",
    "          <td>루트 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:nth-child(n)</code></td>\n",
    "          <td>n번째 자식 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:nth-last-child(n)</code></td>\n",
    "          <td>뒤에서 n번째 자식 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:nth-of-type(n)</code></td>\n",
    "          <td>n번째 해당 종류의 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:first-child</code></td>\n",
    "          <td>첫 번째 자식 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:last-child</code></td>\n",
    "          <td>마지막 자식 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:first-of-type</code></td>\n",
    "          <td>첫 번째 해당 종류의 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:last-of-type</code></td>\n",
    "          <td>마지막 해당 종류의 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:only-child</code></td>\n",
    "          <td>자식으로 유일한 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:only-of-child</code></td>\n",
    "          <td>자식으로 유일한 종류의 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:empty</code></td>\n",
    "          <td>내용이 없는 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:lang(code)</code></td>\n",
    "          <td>특정 언어로 code를 지정한 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:not(s)</code></td>\n",
    "          <td>s 이외의 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:anabled</code></td>\n",
    "          <td>활성화된 UI 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:disabled</code></td>\n",
    "          <td>비활성화된 UI 요소</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td><code class=\"highlighter-rouge\"><요소>:checked</code></td>\n",
    "          <td>체크되어 있는 UI 요소</td>\n",
    "        </tr>\n",
    "      </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSS_Sel.html\n",
    "```\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\" />\n",
    "        <meta name=\"keywords\" content=\"CSS, HTML\" />\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "            <title>CSS 선택자</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>파이썬 프로그램</h1>\n",
    "        <ul class=\"items\">\n",
    "            <li id=\"basic\"><a href=\"/Python/Basics\">Python 기초</a></li>\n",
    "            <li id=\"gui\"><a href=\"/Python/Gui\">GUI 프로그래밍</a></li>\n",
    "            <li id=\"data\"><a href=\"/Python/Data\">Python 데이타</a></li>\n",
    "            <li id=\"djg\"><a href=\"/Python/Django\">Django 기초</a></li>\n",
    "            <li id=\"app\"><a href=\"/Python/Applications\">Python 활용</a></li>\n",
    "            <li id=\"tip\"><a href=\"/Python/Tips\">Python 팁</a></li>\n",
    "            <li id=\"cont\"><a href=\"/Home/Contact\">Contact</a></li>\n",
    "            <li id=\"search\"><a href=\"javascript:showSearch()\"><i class=\"fa fa-search\" aria-hidden=\"true\"></i>검색</a></li>\n",
    "        </ul>\n",
    "    </body>\n",
    "    </html>\n",
    "```\n",
    "﻿\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\" />\n",
    "    <meta name=\"keywords\" content=\"CSS, HTML\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "        <title>CSS 선택자</title>\n",
    "</head>\n",
    "<body>\n",
    "\t<h1>파이썬 프로그램</h1>\n",
    "\t<ul class=\"items\">\n",
    "\t\t<li id=\"basic\"><a href=\"/Python/Basics\">Python 기초</a></li>\n",
    "\t\t<li id=\"gui\"><a href=\"/Python/Gui\">GUI 프로그래밍</a></li>\n",
    "\t\t<li id=\"data\"><a href=\"/Python/Data\">Python 데이타</a></li>\n",
    "\t\t<li id=\"djg\"><a href=\"/Python/Django\">Django 기초</a></li>\n",
    "\t\t<li id=\"app\"><a href=\"/Python/Applications\">Python 활용</a></li>\n",
    "\t\t<li id=\"tip\"><a href=\"/Python/Tips\">Python 팁</a></li>\n",
    "\t\t<li id=\"cont\"><a href=\"/Home/Contact\">Contact</a></li>\n",
    "\t\t<li id=\"search\"><a href=\"javascript:showSearch()\"><i class=\"fa fa-search\" aria-hidden=\"true\"></i>검색</a></li>\n",
    "\t</ul>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n",
      "Python 활용\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 호출\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 파일 열기\n",
    "fp = open('C:/workspace/KSA\\data/modeule04/ch01/CSS_Sel.html', 'r',\n",
    "         encoding='utf-8')\n",
    "\n",
    "soup = BeautifulSoup(fp, 'html.parser') # BeautifulSoup 객체 생성\n",
    "\n",
    "# CSS 선택자로 추출하기\n",
    "sel = lambda q : print(soup.select_one(q).string)\n",
    "sel('#app') # id 속성이 app인 것을 추출\n",
    "sel('li#app') # li 태그에서 id 속성이 app인 것을 추출\n",
    "sel('ul > li#app') # ul 태그의 자식 li 태그에서 id 속성이 app인 것을 추축\n",
    "sel('.items #app') # class='items' 다음에 id='app' 선택\n",
    "sel('.items > #app') # class='items' 자식의 id='app' 선택\n",
    "sel('ul.items > li#app') # ul 태그 class='items' 자식의 li 태그 id='app' 선택\n",
    "\n",
    "sel('li[id=\\'app\\']') # id='app'인 li 태그 (속성 검색 방법)\n",
    "sel('li:nth-of-type(5)') # 5번째 li 태그 선택\n",
    "\n",
    "# select와 find_all 메서드 사용\n",
    "print(soup.select('li')[4].string)\n",
    "print(soup.find_all('li')[4].string)\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fr_ve.html\n",
    "```\n",
    "﻿\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\" />\n",
    "    <meta name=\"keywords\" content=\"CSS, HTML\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "        <title>CSS 선택자</title>\n",
    "</head>\n",
    "<body>\n",
    "\t<div id=\"main-goods\" role=\"page\">\n",
    "\t<h1>과일과 야채</h1>\n",
    "\t<ul id=\"fr-list\">\n",
    "\t\t<li class=\"red green\" data-lo=\"ko\">사과</li>\n",
    "\t\t<li class=\"purple\" data-lo=\"us\">포도</li>\n",
    "\t\t<li class=\"yellow\" data-lo=\"us\">레몬</li>\n",
    "\t\t<li class=\"yellow\" data-lo=\"ko\">오렌지</li>\n",
    "\t</ul>\n",
    "\t<ul id=\"ve-list\">\n",
    "\t\t<li class=\"white green\" data-lo=\"ko\">무</li>\n",
    "\t\t<li class=\"red green\" data-lo=\"us\">파프리카</li>\n",
    "\t\t<li class=\"black\" data-lo=\"us\">가지</li>\n",
    "\t\t<li class=\"black\" data-lo=\"us\">아보카도</li>\n",
    "\t\t<li class=\"white\" data-lo=\"ko\">연근</li>\n",
    "\t</ul>\n",
    "\t</div>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "﻿\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\" />\n",
    "    <meta name=\"keywords\" content=\"CSS, HTML\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "        <title>CSS 선택자</title>\n",
    "</head>\n",
    "<body>\n",
    "\t<div id=\"main-goods\" role=\"page\">\n",
    "\t<h1>과일과 야채</h1>\n",
    "\t<ul id=\"fr-list\">\n",
    "\t\t<li class=\"red green\" data-lo=\"ko\">사과</li>\n",
    "\t\t<li class=\"purple\" data-lo=\"us\">포도</li>\n",
    "\t\t<li class=\"yellow\" data-lo=\"us\">레몬</li>\n",
    "\t\t<li class=\"yellow\" data-lo=\"ko\">오렌지</li>\n",
    "\t</ul>\n",
    "\t<ul id=\"ve-list\">\n",
    "\t\t<li class=\"white green\" data-lo=\"ko\">무</li>\n",
    "\t\t<li class=\"red green\" data-lo=\"us\">파프리카</li>\n",
    "\t\t<li class=\"black\" data-lo=\"us\">가지</li>\n",
    "\t\t<li class=\"black\" data-lo=\"us\">아보카도</li>\n",
    "\t\t<li class=\"white\" data-lo=\"ko\">연근</li>\n",
    "\t</ul>\n",
    "\t</div>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아보카도 \n",
      "\n",
      "오렌지\n",
      "아보카도\n"
     ]
    }
   ],
   "source": [
    "# 파일 열기\n",
    "fp = open('C:/workspace/KSA\\data/modeule04/ch01/fr_ve.html', 'r',\n",
    "         encoding='utf-8')\n",
    "\n",
    "soup = BeautifulSoup(fp, 'html.parser') # BeautifulSoup 객체 생성\n",
    "\n",
    "# CSS 선택자로 추출하기\n",
    "# 두 번째 ul 태그의 4번째 요소\n",
    "print(soup.select_one('ul:nth-of-type(2) > li:nth-of-type(4)').string, '\\n') # 1, 2, 3, 4로 센다\n",
    "\n",
    "# li 태그의 4번째 요소\n",
    "frve_list = soup.select('li:nth-of-type(4)')\n",
    "for st in frve_list:\n",
    "    print(st.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아보카도 \n",
      "\n",
      "파프리카 \n",
      "\n",
      "가지 \n",
      "\n",
      "가지\n",
      "가지\n"
     ]
    }
   ],
   "source": [
    "# id='ve_list'의 자식 li 태그의 data-lo 속성이 'us'\n",
    "print(soup.select('#ve-list > li[data-lo=\\'us\\']')[2].string, '\\n')\n",
    "\n",
    "# id='ve_list'의 자식 li 태그의 class='red'\n",
    "print(soup.select('#ve-list > li.red')[0].string, '\\n')\n",
    "\n",
    "# find 메서드 사용\n",
    "# data-lo가 us, class가 black인 것 찾기\n",
    "cond = {'data-lo' : 'us', 'class' : 'black'}\n",
    "print(soup.find('li', cond).string, '\\n')\n",
    "\n",
    "# find 메서드 연속 사용\n",
    "print(soup.find(id='ve-list').find('li', cond).string)\n",
    "print(soup.find(attrs={'id':'ve-list'}).find('li', cond).string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### 링크에 있는 것을 한꺼번에 내려 받기\n",
    "- 링크 대상이 상대 경로일 때는 HTML의 내용에 추가적인 처리가 필요\n",
    "- 상대 경로를 절대 경로로\n",
    "    - `urllib.parse.urljoin(base, path)`를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.com/tml/a.html \n",
      "\n",
      "http://example.com/tml/b.html\n",
      "http://example.com/tml/sub/c.html\n",
      "http://example.com/index.html\n",
      "http://example.com/image/img/png\n",
      "http://example.com/css/css_doc.css \n",
      "\n",
      "http://www.naver.com\n",
      "http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "# 기본주소\n",
    "base = 'http://example.com/tml/a.html'\n",
    "\n",
    "# 상대주소를 절대주소로 처리\n",
    "print(base, '\\n')\n",
    "print(urljoin(base, 'b.html'))\n",
    "print(urljoin(base, 'sub/c.html'))\n",
    "print(urljoin(base, '../index.html'))\n",
    "print(urljoin(base, '../image/img/png'))\n",
    "print(urljoin(base, '../css/css_doc.css'), '\\n')\n",
    "\n",
    "# 절대주소 입력(기존의 주소 무시)\n",
    "print(urljoin(base, 'http://www.naver.com'))\n",
    "print(urljoin(base, '//www.daum.net'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 재귀적으로 HTML 페이지 처리\n",
    "    - 'a.html'에서 'b.html'로 링크 이동하고, 'b.html'에서 'c.html'로 링크하여 이동하는 경우, 3개의 페이지를 모두 다운로드하여 분석하는 것이 필요\n",
    "    - 이러한 구조의 데이터는 함수를 이용한 재귀 처리\n",
    "        - 어떤 함수 내부에서 해당함수 자신을 호출하는 것이 재귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [1]\n",
    "test += [2]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze html= https://docs.python.org/3.5/library/ \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/intro.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/functions.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/constants.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/stdtypes.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/exceptions.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/text.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/string.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/re.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/difflib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/textwrap.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/unicodedata.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/stringprep.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/readline.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/rlcompleter.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/binary.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/struct.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/codecs.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/datatypes.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/datetime.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/calendar.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/collections.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/collections.abc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/heapq.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/bisect.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/array.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/weakref.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/types.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/copy.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pprint.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/reprlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/enum.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/numeric.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/numbers.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/math.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/cmath.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/decimal.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/fractions.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/random.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/statistics.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/functional.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/itertools.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/functools.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/operator.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/filesys.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pathlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/os.path.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/fileinput.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/stat.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/filecmp.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tempfile.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/glob.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/fnmatch.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/linecache.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/shutil.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/macpath.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/persistence.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pickle.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/copyreg.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/shelve.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/marshal.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/dbm.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/sqlite3.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/archiving.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/zlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/gzip.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/bz2.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/lzma.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/zipfile.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tarfile.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/fileformats.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/csv.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/configparser.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/netrc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xdrlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/plistlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/crypto.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/hashlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/hmac.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/allos.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/os.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/io.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/time.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/argparse.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/getopt.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/logging.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/logging.config.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/logging.handlers.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/getpass.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/curses.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/curses.ascii.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/curses.panel.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/platform.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/errno.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ctypes.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/concurrency.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/threading.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/multiprocessing.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/concurrent.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/concurrent.futures.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/subprocess.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/sched.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/queue.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/dummy_threading.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/_thread.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/_dummy_thread.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ipc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/socket.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ssl.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/select.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/selectors.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-eventloop.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-eventloops.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-task.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-protocol.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-stream.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-subprocess.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-sync.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-queue.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncio-dev.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asyncore.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/asynchat.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/signal.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/mmap.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/netdata.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.message.html \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze html= https://docs.python.org/3.5/library/email.parser.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.generator.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.policy.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.headerregistry.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.contentmanager.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.mime.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.header.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.charset.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.encoders.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.errors.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.util.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email.iterators.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/email-examples.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/json.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/mailcap.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/mailbox.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/mimetypes.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/base64.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/binhex.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/binascii.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/quopri.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/uu.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/markup.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/html.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/html.parser.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/html.entities.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.etree.elementtree.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.dom.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.dom.minidom.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.dom.pulldom.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.sax.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.sax.handler.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.sax.utils.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xml.sax.reader.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pyexpat.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/internet.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/webbrowser.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/cgi.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/cgitb.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/wsgiref.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/urllib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/urllib.request.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/urllib.parse.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/urllib.error.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/urllib.robotparser.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/http.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/http.client.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ftplib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/poplib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/imaplib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/nntplib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/smtplib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/smtpd.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/telnetlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/uuid.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/socketserver.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/http.server.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/http.cookies.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/http.cookiejar.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xmlrpc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xmlrpc.client.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/xmlrpc.server.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ipaddress.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/mm.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/audioop.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/aifc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/sunau.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/wave.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/chunk.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/colorsys.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/imghdr.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/sndhdr.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ossaudiodev.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/i18n.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/gettext.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/locale.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/frameworks.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/turtle.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/cmd.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/shlex.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tk.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tkinter.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tkinter.ttk.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tkinter.tix.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tkinter.scrolledtext.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/idle.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/othergui.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/development.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/typing.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pydoc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/doctest.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/unittest.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/unittest.mock.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/unittest.mock-examples.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/2to3.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/test.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/debug.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/bdb.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/faulthandler.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pdb.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/profile.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/timeit.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/trace.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tracemalloc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/distribution.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/distutils.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ensurepip.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/venv.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/zipapp.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/python.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/sys.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/sysconfig.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/builtins.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/__main__.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/warnings.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/contextlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/abc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/atexit.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/traceback.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/__future__.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/gc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/inspect.html \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze html= https://docs.python.org/3.5/library/site.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/fpectl.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/custominterp.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/code.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/codeop.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/modules.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/zipimport.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pkgutil.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/modulefinder.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/runpy.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/importlib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/language.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/parser.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/ast.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/symtable.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/symbol.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/token.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/keyword.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tokenize.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tabnanny.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pyclbr.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/py_compile.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/compileall.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/dis.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pickletools.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/misc.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/formatter.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/windows.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/msilib.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/msvcrt.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/winreg.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/winsound.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/unix.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/posix.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pwd.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/spwd.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/grp.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/crypt.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/termios.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/tty.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pty.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/fcntl.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/pipes.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/resource.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/nis.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/syslog.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/superseded.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/optparse.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/imp.html \n",
      "\n",
      "analyze html= https://docs.python.org/3.5/library/undoc.html \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 메뉴얼을 재귀적으로 다운받는 프로그램\n",
    "# 모튤 호출 --- (%1)\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import *\n",
    "from urllib.parse import *\n",
    "from os import makedirs\n",
    "import os.path, time, re\n",
    "\n",
    "# 이미 처리한 파일인지 확인하기 위한 변수 --- (%2)\n",
    "proc_files = {}\n",
    "\n",
    "# HTML 내부에 있는 링크를 추출하는 함수 --- (%3)\n",
    "def enum_links(html, base):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = soup.select('link[re=\\'stylesheet\\']') # CSS\n",
    "    links += soup.select('a[href]') # 링크\n",
    "    result = []\n",
    "    # href를 추출하고, 링크를 절대 경로로 변환 --- (%4)\n",
    "    for a in links:\n",
    "        href = a.attrs['href']\n",
    "        url = urljoin(base, href)\n",
    "        result.append(url)\n",
    "    return result\n",
    "\n",
    "# 파일을 다운받고 저장하는 함수 --- (%5)\n",
    "dir_path = 'C:\\workspace\\KSA\\data\\modeule04\\ch01'.replace('\\\\', '/') + '/'\n",
    "\n",
    "def download_file(url, dir_path):\n",
    "    \"\"\"\n",
    "    1. url과 data_path를 받는다.\n",
    "    2. data_path(상위 directory)와 domain(host), path를 합쳐 docs를 저장할 \n",
    "        path를 만든다.\n",
    "    3. re.search로 /로 끝나는지 (폴더인지) 체크한다\n",
    "        만일 /로 끝난다면, index.html을 savepath에 추가하고 이를 반환한다.\n",
    "        만일 아니라면, url의 데이터를 다운로드하고 savepath를 반환한다.\n",
    "    \"\"\"\n",
    "    o = urlparse(url)\n",
    "    savepath = dir_path + o.netloc + o.path # netloc : 네트워크 위치\n",
    "    if re.search(r\"/$\", savepath): # 폴더라면 index.html\n",
    "        savepath += 'index.html'\n",
    "    savedir = os.path.dirname(savepath)\n",
    "    # 모두 다운됐는지 확인\n",
    "    if os.path.exists(savepath):\n",
    "        return savepath\n",
    "    if not os.path.exists(savedir):\n",
    "        print('mkdir=', savedir)\n",
    "        makedirs(savedir)\n",
    "    # 파일 다운받기 --- (%6)\n",
    "    try:\n",
    "        print('download=', url)\n",
    "        urlretrieve(url, savepath)\n",
    "        time.sleep(1) # 1초 휴식 --- (%7)\n",
    "        return savepath\n",
    "    except:\n",
    "        print('다운 실패: ', url)\n",
    "        return None\n",
    "\n",
    "# HTML을 분석하고 다운받는 함수 --- (%8)\n",
    "def analyze_html(url, root_url, dir_path):\n",
    "    savepath = download_file(url, dir_path)\n",
    "    if savepath is None:\n",
    "        return None\n",
    "    # 이미 처리되었다면 실행하지 않음 --- (%9)\n",
    "    if savepath in proc_files:\n",
    "        return None\n",
    "    proc_files[savepath] = True\n",
    "    print('analyze html=', url, '\\n')\n",
    "    # 링크 추출 --- (%10)\n",
    "    html = open(savepath, 'r', encoding='utf-8').read()\n",
    "    links = enum_links(html, url)\n",
    "    for link_url in links:\n",
    "        # 링크가 루트 이외의 경로를 나타낸다면 무시 --- (%11)\n",
    "        if link_url.find(root_url) != 0:\n",
    "            if not re.search(r\".css$\", link_url):\n",
    "                continue\n",
    "        # HTML이라면\n",
    "        if re.search(r\".(html|htm)$\", link_url):\n",
    "            # 재귀적으로 HTML 파일 분석하기\n",
    "            analyze_html(link_url, root_url, dir_path)\n",
    "            continue\n",
    "        # 기타 파일\n",
    "        download_file(link_url, dir_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # url에 있는 모든 것 다운받기 --- (%12)\n",
    "    url = 'https://docs.python.org/3.5/library/'\n",
    "    analyze_html(url, url, dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 행으로 넘어갈 때는 개행 문자(\\n)을 쓰세요.\n"
     ]
    }
   ],
   "source": [
    "print(r'다음 행으로 넘어갈 때는 개행 문자(\\n)을 쓰세요.') # escape 문자를 그대로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스크립터가 위치한 디렉토리\n",
      "dirname:\tC:\\Users\\Affinity\\.conda\\envs\\ds\\lib\n",
      "현재 작업 중인 디렉토리\n",
      "getcwd:\t\tC:\\workspace\\KSA\\Module 4. Big Data preprocess\n"
     ]
    }
   ],
   "source": [
    "print('스크립터가 위치한 디렉토리')\n",
    "print(\"dirname:\\t\" + os.path.dirname(os.path.abspath(os.__file__)))\n",
    "print('현재 작업 중인 디렉토리')\n",
    "print(\"getcwd:\\t\\t\" + os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 재귀적으로 파일을 읽는 함수 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/workspace/KSA/data/modeule04/ch01/'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = 'C:\\workspace\\KSA\\data\\modeule04\\ch01'.replace('\\\\', '/') + '/'\n",
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='docs.python.org', path='/3.5/library/', params='', query='', fragment='')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://docs.python.org/3.5/library/'\n",
    "root_url = url\n",
    "o = urlparse(url)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/workspace/KSA/data/modeule04/ch01/docs.python.org/3.5/library/'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savepath = dir_path + o.netloc + o.path\n",
    "savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.search(r\"/$\", savepath):\n",
    "    savepath += 'index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/workspace/KSA/data/modeule04/ch01/docs.python.org/3.5/library/index.html',\n",
       " 'C:/workspace/KSA/data/modeule04/ch01/docs.python.org/3.5/library')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedir = os.path.dirname(savepath)\n",
    "savepath, savedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(savepath):\n",
    "    print('exist')\n",
    "else:\n",
    "    print('Not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 없을 시 directory 생성\n",
    "if not os.path.exists(savedir):\n",
    "    makedirs(savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/workspace/KSA/data/modeule04/ch01/docs.python.org/3.5/library/index.html',\n",
       " <http.client.HTTPMessage at 0x2bba2663a20>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve(url, savepath) # download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 링크추출\n",
    "html = open(savepath, 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enum_links ---------------------------------------------\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = soup.select('link[re|=\\'stylesheet\\']')\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a accesskey=\"I\" href=\"../genindex.html\" title=\"General Index\">index</a>,\n",
       " <a href=\"../py-modindex.html\" title=\"Python Module Index\">modules</a>,\n",
       " <a accesskey=\"N\" href=\"intro.html\" title=\"1. Introduction\">next</a>,\n",
       " <a accesskey=\"P\" href=\"../reference/grammar.html\" title=\"10. Full Grammar specification\">previous</a>,\n",
       " <a href=\"https://www.python.org/\">Python</a>,\n",
       " <a href=\"../index.html\">3.5.7 Documentation</a>,\n",
       " <a class=\"headerlink\" href=\"#the-python-standard-library\" title=\"Permalink to this headline\">¶</a>,\n",
       " <a class=\"reference internal\" href=\"../reference/index.html#reference-index\"><span class=\"std std-ref\">The Python Language Reference</span></a>,\n",
       " <a class=\"reference external\" href=\"https://pypi.python.org/pypi\">Python Package Index</a>,\n",
       " <a class=\"reference internal\" href=\"intro.html\">1. Introduction</a>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests += soup.select('a[href]') # a tag의 href속성을 가지는 놈을 전부 호출\n",
    "tests[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../genindex.html'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href = tests[0].attrs['href']\n",
    "href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://docs.python.org/3.5/genindex.html'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urljoin(url, href) # 이런 식으로 모두 합치면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://docs.python.org/3.5/genindex.html',\n",
       " 'https://docs.python.org/3.5/py-modindex.html',\n",
       " 'https://docs.python.org/3.5/library/intro.html',\n",
       " 'https://docs.python.org/3.5/reference/grammar.html',\n",
       " 'https://www.python.org/',\n",
       " 'https://docs.python.org/3.5/index.html',\n",
       " 'https://docs.python.org/3.5/library/#the-python-standard-library',\n",
       " 'https://docs.python.org/3.5/reference/index.html#reference-index',\n",
       " 'https://pypi.python.org/pypi',\n",
       " 'https://docs.python.org/3.5/library/intro.html',\n",
       " 'https://docs.python.org/3.5/library/functions.html',\n",
       " 'https://docs.python.org/3.5/library/constants.html',\n",
       " 'https://docs.python.org/3.5/library/constants.html#constants-added-by-the-site-module',\n",
       " 'https://docs.python.org/3.5/library/stdtypes.html',\n",
       " 'https://docs.python.org/3.5/library/stdtypes.html#truth-value-testing',\n",
       " 'https://docs.python.org/3.5/library/stdtypes.html#boolean-operations-and-or-not',\n",
       " 'https://docs.python.org/3.5/library/stdtypes.html#comparisons',\n",
       " 'https://docs.python.org/3.5/library/stdtypes.html#numeric-types-int-float-complex',\n",
       " 'https://docs.python.org/3.5/library/stdtypes.html#iterator-types',\n",
       " 'https://docs.python.org/3.5/library/stdtypes.html#sequence-types-list-tuple-range']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze_html ----------------------------------------\n",
    "links = enum_links(html, url)\n",
    "links[:20] # index.html에서 python docs link를 받아옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://docs.python.org/3.5/library/ \n",
      "\n",
      "link_url.find(root_url) != 0에 걸리는 친구들\n",
      "\n",
      "https://docs.python.org/3.5/genindex.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/py-modindex.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/reference/grammar.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://www.python.org/\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/index.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/reference/index.html#reference-index\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://pypi.python.org/pypi\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/reference/grammar.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/bugs.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://github.com/python/cpython/blob/3.5/Doc/library/index.rst\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/genindex.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/py-modindex.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/reference/grammar.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://www.python.org/\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/index.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/copyright.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://www.python.org/psf/donations/\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "https://docs.python.org/3.5/bugs.html\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n",
      "http://sphinx.pocoo.org/\n",
      " 이 link를 제외하고 진행할까요? True면 제외 : True\n"
     ]
    }
   ],
   "source": [
    "print(root_url, '\\n')\n",
    "print('link_url.find(root_url) != 0에 걸리는 친구들\\n')\n",
    "for link_url in [link for link in links if link.find(root_url) != 0]:\n",
    "    print(link_url)\n",
    "    print(' 이 link를 제외하고 진행할까요? True면 제외 :', not re.search(r\".css$\", link_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막에 세 가지 분기가 존재\n",
    "    - 위의 조건이면 continue(link 무시)\n",
    "    - HTML이거나 HTM이면 analyze_html 재 실행\n",
    "        - 파일 다운로드부터\n",
    "        - link끄내오기 재 실행\n",
    "    - 위 두 조건을 만족시키지 않으면,\n",
    "        - download_file 실행하여 url download"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
