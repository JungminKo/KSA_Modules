{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    '''2층 신경망 구현'''\n",
    "    def __init__(self, input_size, \n",
    "                 hidden_size, output_size, weight_init_std=0.01):\n",
    "        '''\n",
    "        초기화 수행\n",
    "        Params:\n",
    "            - input_size: 입력층 뉴런 수\n",
    "            - hidden_size: 은닉층 뉴런 수\n",
    "            - output_size: 출력층 뉴런 수\n",
    "            - weight_init_std: 가중치 초기화 시 정규분포의 스케일\n",
    "        '''\n",
    "        # 가중치 초기화\n",
    "        self.params = {\n",
    "            'W1': weight_init_std * np.random.randn(input_size, hidden_size),\n",
    "            'b1': np.zeros(hidden_size),\n",
    "            'W2': weight_init_std * np.random.randn(hidden_size, output_size),\n",
    "            'b2': np.zeros(output_size)\n",
    "        }\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict({\n",
    "            'Affine1': Affine(self.params['W1'], self.params['b1']),\n",
    "            'Relu1': Relu(),\n",
    "            'Affine2': Affine(self.params['W2'], self.params['b2'])\n",
    "        })\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''예측(추론)\n",
    "            Pararms:\n",
    "                - x: 이미지 데이터'''\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        '''\n",
    "        손실함수의 값을 계산\n",
    "        Params:\n",
    "            - x: 이미지데이터, t: 정답 레이블\n",
    "        '''\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        '''\n",
    "        정확도 계산\n",
    "        Params:\n",
    "            - x: 이미지 데이터\n",
    "            - t: 정답 레이블\n",
    "        '''\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1:\n",
    "            t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        '''\n",
    "        미분을 통한 가중치 매개변수의 기울기 계산\n",
    "        Params:\n",
    "            - x: 이미지 데이터\n",
    "            - t: 정답 레이블 \n",
    "        '''\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {\n",
    "            'W1': numerical_gradient(loss_W, self.params['W1']),\n",
    "            'b1': numerical_gradient(loss_W, self.params['b1']),\n",
    "            'W2': numerical_gradient(loss_W, self.params['W2']),\n",
    "            'b2': numerical_gradient(loss_W, self.params['b2'])\n",
    "        }\n",
    "        return grads\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # 결과 저장\n",
    "        grads = {\n",
    "            'W1': self.layers['Affine1'].dW, 'b1': self.layers['Affine1'].db,\n",
    "            'W2': self.layers['Affine2'].dW, 'b2': self.layers['Affine2'].db\n",
    "        }\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 : 3.864104453654888e-10\n",
      "b1 : 2.3828968641836055e-09\n",
      "W2 : 4.639392628674223e-09\n",
      "b2 : 1.394510603394683e-07\n",
      "Wall time: 5.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# mnist load\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=28*28, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 절대 오차의 평균을 구한다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "    print(key,\":\", str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어떻게 구동되는지 체크!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 50 10 0.01\n"
     ]
    }
   ],
   "source": [
    "input_size = 28*28; hidden_size=50; output_size=10; weight_init_std=.01;\n",
    "print(input_size, hidden_size, output_size, weight_init_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00341426, -0.00519704,  0.0008543 , ..., -0.00630821,\n",
       "         -0.01050883,  0.0242224 ],\n",
       "        [ 0.01380829,  0.00718157,  0.018027  , ...,  0.01140965,\n",
       "         -0.0189462 ,  0.00074538],\n",
       "        [ 0.01996407, -0.02190384, -0.01841735, ..., -0.02601784,\n",
       "          0.00966829, -0.00208664],\n",
       "        ...,\n",
       "        [-0.0129087 , -0.00222335,  0.02354596, ...,  0.01295494,\n",
       "          0.00692917,  0.00715465],\n",
       "        [ 0.01750363, -0.0083064 ,  0.00989071, ...,  0.01260056,\n",
       "          0.01552843, -0.00333524],\n",
       "        [-0.01494274, -0.00983312, -0.01817081, ..., -0.00294322,\n",
       "          0.0044816 , -0.01783037]]), (784, 50))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "W1, W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " (50,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = np.zeros(hidden_size)\n",
    "b1, b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-9.81194685e-03, -1.66586678e-02, -3.52309052e-03,\n",
       "          6.09391991e-03,  4.88168477e-03,  5.51387926e-03,\n",
       "          9.11183356e-03,  8.23754800e-03, -6.71383723e-03,\n",
       "          1.01050152e-02],\n",
       "        [-4.36406643e-03, -1.40617591e-03, -2.84864604e-03,\n",
       "         -8.35538470e-03,  5.37182161e-03, -2.68788305e-03,\n",
       "         -1.61904515e-02,  5.88367122e-03, -8.87600082e-03,\n",
       "         -1.87540280e-03],\n",
       "        [ 4.10276622e-03,  1.48087151e-03,  1.04899050e-02,\n",
       "          1.15717847e-02, -1.07847112e-02,  8.09617076e-03,\n",
       "         -4.53152028e-03,  1.60437035e-02, -1.05091785e-02,\n",
       "         -1.36420232e-03],\n",
       "        [-5.50599219e-03, -5.50648731e-03,  1.90440022e-03,\n",
       "         -8.65216219e-03,  2.56673991e-03, -2.57621223e-03,\n",
       "          1.03967033e-02, -1.49734761e-02,  7.18339054e-03,\n",
       "          6.70338799e-03],\n",
       "        [ 1.68583000e-02, -1.66124053e-03,  6.54760705e-03,\n",
       "         -1.66367058e-02, -3.44755038e-03,  1.37835605e-02,\n",
       "         -1.16471379e-02, -7.84328148e-04, -1.63636625e-02,\n",
       "         -2.07397562e-02],\n",
       "        [-1.47639128e-02,  5.18862930e-03, -1.25697431e-02,\n",
       "          7.56102750e-03, -1.62119143e-02,  1.37748662e-02,\n",
       "         -1.60886693e-04, -1.61722129e-02,  7.90292127e-03,\n",
       "         -4.69646853e-03],\n",
       "        [-7.21054797e-04,  9.18208906e-03, -1.33861948e-03,\n",
       "         -1.11969680e-03,  3.63724202e-05, -2.40087441e-03,\n",
       "         -9.83340787e-03,  1.19546042e-02,  1.10257801e-02,\n",
       "         -6.69311289e-03],\n",
       "        [-7.26977836e-03,  1.41521967e-02, -5.50565850e-03,\n",
       "         -6.05213298e-03,  6.86092263e-03, -7.09412299e-03,\n",
       "          6.12862266e-03,  4.06382702e-03,  1.79183929e-03,\n",
       "         -3.98108346e-03],\n",
       "        [ 1.99355121e-04,  1.84969720e-02, -5.11434236e-03,\n",
       "          1.99847084e-03,  1.39096607e-03,  2.85403573e-03,\n",
       "          3.28151936e-03, -2.86068563e-02, -3.67908993e-04,\n",
       "         -1.11224320e-02],\n",
       "        [ 8.15351686e-03,  1.44219852e-02, -3.74915038e-03,\n",
       "         -2.03878843e-03, -8.87294843e-03, -6.55940720e-03,\n",
       "          3.43211570e-03, -1.85479950e-02, -8.45103482e-03,\n",
       "          6.64910792e-03],\n",
       "        [-6.35064024e-03, -1.63506795e-02, -1.13847234e-02,\n",
       "         -3.20939947e-03,  6.87942897e-03,  1.53983454e-02,\n",
       "          2.37830803e-03, -6.46038210e-03, -4.69933977e-03,\n",
       "          1.14466977e-03],\n",
       "        [-1.12200126e-02,  7.22672165e-04,  4.58202876e-03,\n",
       "          1.87764333e-03,  3.50122492e-03,  2.09020979e-03,\n",
       "         -6.02872159e-03, -4.74556851e-04, -8.89696311e-03,\n",
       "         -2.31579745e-03],\n",
       "        [-4.91785890e-03, -4.94577272e-03, -2.50129986e-02,\n",
       "         -4.37830793e-03, -3.32308126e-03,  5.49314705e-03,\n",
       "          1.40070979e-02, -1.36925492e-03, -1.12119525e-02,\n",
       "          4.99008389e-03],\n",
       "        [-1.32316147e-02, -4.91890219e-03,  1.03295147e-02,\n",
       "         -1.19046138e-02,  2.04926266e-03, -1.16066970e-02,\n",
       "         -8.94149137e-03,  1.39315837e-02, -4.20269855e-03,\n",
       "         -1.22122776e-02],\n",
       "        [ 2.22955768e-02,  5.55969319e-04,  6.86619759e-03,\n",
       "          6.52983153e-03,  1.54753545e-03,  8.97437419e-03,\n",
       "          4.72415746e-03,  1.12374748e-02,  9.65666384e-03,\n",
       "          2.94465633e-03],\n",
       "        [ 5.38715960e-03,  8.51837016e-03,  1.20142239e-02,\n",
       "          4.51579104e-03,  8.83439935e-03, -5.30623753e-03,\n",
       "         -1.49666724e-02, -1.86148571e-02,  7.93525377e-03,\n",
       "          7.92209621e-03],\n",
       "        [ 3.51279546e-03, -1.75871872e-02, -3.08651034e-03,\n",
       "         -4.66049529e-03, -1.76555596e-02, -5.69075670e-03,\n",
       "         -1.27896148e-02, -4.39365225e-03, -9.76137642e-03,\n",
       "         -3.86019950e-04],\n",
       "        [ 1.08672482e-02,  1.69481413e-03, -4.05254219e-03,\n",
       "         -5.22184232e-03,  5.52708411e-03, -1.03326177e-02,\n",
       "          1.30797808e-02, -1.06761595e-02,  4.98468137e-03,\n",
       "          7.29787481e-03],\n",
       "        [ 5.12080700e-03,  7.73212523e-03,  1.59888960e-02,\n",
       "          9.53546198e-03, -1.51072689e-02,  3.72638668e-03,\n",
       "         -6.52961346e-03, -1.21393581e-03, -1.22573333e-02,\n",
       "          1.15973232e-02],\n",
       "        [ 1.10103877e-02,  1.78856937e-02,  6.79899094e-03,\n",
       "         -7.60318988e-03,  2.45432949e-03,  1.98419435e-03,\n",
       "          3.91604883e-03,  2.96928447e-03, -7.68547104e-03,\n",
       "          9.47795736e-03],\n",
       "        [-3.29482089e-03,  2.06935462e-05, -7.86449177e-03,\n",
       "         -3.44277867e-03, -7.16938673e-03, -2.13593770e-02,\n",
       "         -5.69547425e-03, -4.46174244e-03, -1.48545415e-02,\n",
       "          7.22794297e-03],\n",
       "        [-2.60332727e-03,  1.71110687e-04, -8.57047573e-03,\n",
       "         -5.53509998e-03,  1.51517970e-02,  1.54574650e-02,\n",
       "          5.97974171e-03,  1.25056079e-03,  9.51983901e-03,\n",
       "          5.73121145e-03],\n",
       "        [-1.41708221e-02, -8.10915734e-03,  4.36433771e-03,\n",
       "         -5.81505075e-03, -1.73518648e-02,  6.16563947e-04,\n",
       "         -1.16308610e-02, -6.90674217e-03, -4.63473960e-04,\n",
       "          1.40282577e-02],\n",
       "        [ 1.53456721e-02,  5.27565964e-03,  2.75967659e-03,\n",
       "          1.20886443e-02,  1.49020168e-02, -1.74360600e-02,\n",
       "          1.55303297e-02,  1.14361961e-02,  1.41918821e-02,\n",
       "         -9.68087744e-03],\n",
       "        [-6.73292784e-03,  2.91035074e-03,  5.89367050e-03,\n",
       "          5.09034866e-03,  9.62365566e-03, -5.97989840e-03,\n",
       "          4.42302866e-03,  1.63846373e-02,  1.53005148e-02,\n",
       "         -6.25388588e-03],\n",
       "        [-7.94883153e-03, -1.06717602e-02,  8.83684667e-03,\n",
       "          9.07229146e-03,  6.99223841e-03,  1.87558961e-02,\n",
       "          4.66398601e-03, -1.02772956e-02, -1.25230292e-02,\n",
       "         -1.41015163e-02],\n",
       "        [ 1.54513236e-02, -1.28255992e-02,  5.46896814e-03,\n",
       "         -9.87142959e-03, -5.30233988e-03, -9.16207920e-03,\n",
       "          2.40841344e-06,  4.50810069e-03,  1.01258658e-02,\n",
       "          9.70373362e-03],\n",
       "        [ 4.10597009e-03,  3.87965113e-03, -2.57404128e-03,\n",
       "          1.77024505e-03,  1.46786046e-03,  4.58258740e-03,\n",
       "          1.80852192e-02,  8.49974731e-03, -9.18843657e-03,\n",
       "          8.22506005e-03],\n",
       "        [ 1.75132123e-03,  3.99909133e-03, -2.60454993e-03,\n",
       "         -7.62016793e-03,  1.07705590e-02, -2.78024621e-03,\n",
       "          1.02954393e-02,  9.03809378e-03, -1.24598296e-03,\n",
       "          1.31479632e-02],\n",
       "        [ 1.00768839e-02, -3.37157239e-03, -7.80598560e-03,\n",
       "         -6.54810050e-04,  2.27102595e-02,  1.14378224e-02,\n",
       "          8.32531728e-03, -3.07490164e-02, -1.10620643e-02,\n",
       "          4.73502466e-03],\n",
       "        [-8.73703295e-03, -1.02291172e-02,  4.57769579e-03,\n",
       "          1.78569364e-02,  5.01116156e-03,  2.08966673e-02,\n",
       "         -6.33889821e-03,  1.39899900e-02, -1.78875737e-04,\n",
       "          5.15401561e-03],\n",
       "        [ 2.98008972e-02, -1.56784092e-03, -9.60240805e-03,\n",
       "          4.47851041e-03,  4.70345682e-03,  1.00720304e-02,\n",
       "         -1.85629692e-03, -1.83790055e-02, -1.01672485e-02,\n",
       "          7.49300864e-03],\n",
       "        [ 1.70218124e-02,  1.97593963e-02, -7.27675133e-03,\n",
       "         -2.18738414e-03,  6.05832577e-03, -1.08932352e-02,\n",
       "         -9.83875289e-03, -4.00893441e-03, -2.61466851e-03,\n",
       "          2.83430597e-03],\n",
       "        [-2.85054010e-03, -5.67574212e-03, -8.17568213e-04,\n",
       "          1.09044983e-02,  8.68741427e-03,  3.97005111e-03,\n",
       "         -7.01455734e-03, -2.97665510e-03,  6.23272007e-03,\n",
       "          2.86864405e-03],\n",
       "        [ 4.50343674e-03, -4.53945126e-04, -2.64943076e-03,\n",
       "         -1.03706977e-03, -4.64240294e-03,  1.04342281e-02,\n",
       "          2.57060914e-03,  3.02096907e-03, -1.06634149e-02,\n",
       "         -2.00268534e-03],\n",
       "        [-1.15336967e-02, -1.01439233e-02,  1.78904929e-03,\n",
       "         -1.07354863e-02, -2.92377201e-03, -4.47219236e-03,\n",
       "          9.82425355e-03,  3.16004180e-03,  2.69675494e-03,\n",
       "          1.52624570e-02],\n",
       "        [-8.61317995e-03,  1.10567143e-02,  2.03012897e-02,\n",
       "          7.73279799e-03,  2.39911026e-03,  7.45572979e-04,\n",
       "          7.14746103e-03,  9.23734793e-03, -1.34059315e-02,\n",
       "         -1.04580636e-03],\n",
       "        [-7.48235294e-03, -1.90718445e-02,  5.52586461e-03,\n",
       "         -2.11737125e-03,  1.26969035e-02,  9.34206538e-04,\n",
       "         -4.84079453e-03, -9.55522052e-03, -3.95688908e-03,\n",
       "          1.26021898e-03],\n",
       "        [-3.23558766e-03,  7.52154939e-03, -2.32058200e-03,\n",
       "          2.72206424e-03, -4.90652717e-04,  9.30348001e-03,\n",
       "          2.10619009e-02, -2.55602264e-03,  1.01804139e-02,\n",
       "          4.28015534e-03],\n",
       "        [ 1.32144272e-04,  4.38314825e-03,  9.80211226e-03,\n",
       "          9.99875410e-03, -1.73730546e-03, -9.23920066e-03,\n",
       "         -4.59154999e-03, -1.68821445e-02, -5.77053270e-03,\n",
       "          6.06012943e-03],\n",
       "        [-8.11441981e-03, -4.87943289e-03,  6.38238439e-03,\n",
       "          9.04486657e-03, -7.92528378e-03, -1.20425759e-02,\n",
       "         -5.81868346e-03,  6.96331538e-03,  2.53781531e-03,\n",
       "         -8.62573844e-03],\n",
       "        [ 8.53199236e-03,  8.20649581e-03,  3.22718677e-03,\n",
       "         -2.46340012e-03,  1.05483530e-04, -3.36477701e-03,\n",
       "         -6.29224504e-03, -1.40001179e-02, -7.96623878e-04,\n",
       "         -2.15875780e-02],\n",
       "        [-1.16405034e-02, -7.29522171e-03, -7.01007038e-04,\n",
       "          4.17757179e-03,  1.17242720e-02,  2.74963383e-03,\n",
       "         -6.77585748e-03,  8.19323312e-03,  1.09064453e-02,\n",
       "          6.56315069e-03],\n",
       "        [-1.67728844e-02, -6.43209439e-03,  8.25035670e-03,\n",
       "          1.49215960e-03, -9.04843461e-04,  3.58578914e-03,\n",
       "          7.82613468e-06,  1.16220607e-02,  6.69537434e-03,\n",
       "          1.01422021e-02],\n",
       "        [-7.19823260e-03,  3.31502466e-03, -3.69557375e-03,\n",
       "         -6.64694844e-03,  1.21846428e-02,  1.10286901e-02,\n",
       "          2.45875917e-03,  4.68710218e-03,  3.98095524e-04,\n",
       "          4.84897106e-03],\n",
       "        [ 9.48561920e-03, -1.11212307e-02, -2.63904398e-03,\n",
       "         -5.07068525e-03, -1.87188063e-02,  1.73332389e-03,\n",
       "          8.72524895e-03, -1.02062913e-02,  5.24703256e-03,\n",
       "         -5.25557595e-03],\n",
       "        [-9.87001209e-03, -2.21991670e-03, -8.73265986e-03,\n",
       "          8.52768958e-03, -1.93669871e-03, -1.42455023e-02,\n",
       "          2.61387224e-03,  5.13441338e-03,  4.44154941e-03,\n",
       "         -9.33455039e-03],\n",
       "        [-6.01200842e-03,  1.16532797e-03,  1.18550919e-02,\n",
       "          9.16956076e-03, -1.76120934e-02, -8.24603779e-03,\n",
       "          4.84478236e-03,  1.09305668e-02,  3.93804547e-03,\n",
       "         -1.27518758e-02],\n",
       "        [-9.24962853e-04, -1.78134982e-02, -2.27010725e-02,\n",
       "          1.45264434e-02, -3.58807251e-03, -8.94504834e-03,\n",
       "          1.65092709e-02, -4.94835348e-03, -1.36298680e-02,\n",
       "          3.55612669e-04],\n",
       "        [-9.13357524e-03,  7.79460126e-03, -5.93505246e-03,\n",
       "          1.40697713e-02,  6.28104458e-03, -5.89489399e-03,\n",
       "          7.06146821e-03, -1.08311711e-02,  8.33135581e-03,\n",
       "          4.70886387e-03]]), (50, 10))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "W2, W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), (10,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = np.zeros(output_size)\n",
    "b2, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 텐서 대응\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "params = {\n",
    "    'W1':W1, 'b1':b1, 'W2':W2, 'b2':b2\n",
    "}\n",
    "layers = OrderedDict(\n",
    "    {\n",
    "        'Affine1' : Affine(params['W1'], params['b1']),\n",
    "        'Relu1' : Relu(),\n",
    "        'Affine2' : Affine(params['W2'], params['b2'])\n",
    "    }\n",
    ")\n",
    "last_layer = SoftmaxWithLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Affine1', <__main__.Affine at 0x20189db16a0>),\n",
       "             ('Relu1', <__main__.Relu at 0x20189db1400>),\n",
       "             ('Affine2', <__main__.Affine at 0x20189db1518>)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SoftmaxWithLoss at 0x20189db10f0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([5, 0, 4], dtype=uint8),\n",
       " (3, 784),\n",
       " (3,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, t_batch, x_batch.shape, t_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.loss\n",
    "## loss_W = lambda W : loss(x,t)\n",
    "def predict(x):\n",
    "    for layer in layers.values():\n",
    "        x = layer.forward(x)\n",
    "    return x\n",
    " \n",
    "def loss(x, t):\n",
    "    '''\n",
    "    손실함수의 값을 계산\n",
    "    Params:\n",
    "        - x: 이미지데이터, t: 정답 레이블\n",
    "    '''\n",
    "    y = predict(x)\n",
    "    return last_layer.forward(y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 784), (784, 50))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape, W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.dot(W1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "        26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
       "        39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
       "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "        26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
       "        39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n",
       "       [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
       "        26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
       "        39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x_batch, W1) + np.arange(50) - np.dot(x_batch, W1) # broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00630799,  0.00232234,  0.01427654,  0.00253922, -0.01640813,\n",
       "         -0.00598654, -0.00541831, -0.00349949, -0.00075041, -0.00467397],\n",
       "        [-0.00057521,  0.00635793,  0.00107234,  0.00448934, -0.00405301,\n",
       "         -0.0075228 ,  0.00123402, -0.00730456, -0.00057363,  0.00054867],\n",
       "        [ 0.00394519,  0.00324727, -0.00044033, -0.00134341, -0.00050139,\n",
       "          0.00153177, -0.003671  , -0.01426108, -0.00303498,  0.00321731]]),\n",
       " (3, 10))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hidden = np.dot(x_batch, W1) + b1\n",
    "x_output = np.dot(x_hidden, W2) + b2\n",
    "x_output, x_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.09960621, 0.10046956, 0.1016778 , 0.10049135, 0.09860523,\n",
       "         0.09963823, 0.09969486, 0.09988634, 0.10016132, 0.0997691 ],\n",
       "        [0.10000482, 0.10070057, 0.10016971, 0.10051258, 0.09965762,\n",
       "         0.09931243, 0.10018591, 0.09933411, 0.10000497, 0.10011727],\n",
       "        [0.10050764, 0.10043752, 0.10006783, 0.0999775 , 0.10006172,\n",
       "         0.10026537, 0.09974506, 0.09869433, 0.09980852, 0.10043451]]),\n",
       " (3, 10))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = softmax(x_output)\n",
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.303570463083997"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y, t_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ndim==1, t_batch.size==y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = y.shape[0]\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([5, 0, 4], dtype=uint8))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(batch_size), t_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09960621, 0.10046956, 0.1016778 , 0.10049135, 0.09860523,\n",
       "        0.09963823, 0.09969486, 0.09988634, 0.10016132, 0.0997691 ],\n",
       "       [0.10000482, 0.10070057, 0.10016971, 0.10051258, 0.09965762,\n",
       "        0.09931243, 0.10018591, 0.09933411, 0.10000497, 0.10011727],\n",
       "       [0.10050764, 0.10043752, 0.10006783, 0.0999775 , 0.10006172,\n",
       "        0.10026537, 0.09974506, 0.09869433, 0.09980852, 0.10043451]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09963823, 0.10000482, 0.10006172])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[np.arange(batch_size), t_batch] # fancy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.303570463083997"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = -np.sum(np.log(y[np.arange(batch_size), t_batch] + 1e-7)) / batch_size\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "## numerical_gradient(loss_W, params['W1'])\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x) # f(x+h)\n",
    "        \n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) # f(x-h)\n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        \n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 50)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 1e-4\n",
    "grad = np.zeros_like(W1)\n",
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.nditer at 0x2018a439c10>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = np.nditer(w1, flags=['multi_index'], op_flags=['readwrite'])\n",
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_W = lambda W : loss(x_batch, t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not it.finished:\n",
    "    idx = it.multi_index\n",
    "    tmp_val = W1[idx]\n",
    "    W1[idx] = float(tmp_val) + h\n",
    "    fxh1 = loss_W(W1) # f(x+h)\n",
    "\n",
    "    W1[idx] = tmp_val - h \n",
    "    fxh2 = loss_W(w1) # f(x-h)\n",
    "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "\n",
    "    W1[idx] = tmp_val # 값 복원\n",
    "    it.iternext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.19138482495462128"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00341426, -0.00519704,  0.0008543 , ..., -0.00630821,\n",
       "        -0.01050883,  0.0242224 ],\n",
       "       [ 0.01380829,  0.00718157,  0.018027  , ...,  0.01140965,\n",
       "        -0.0189462 ,  0.00074538],\n",
       "       [ 0.01996407, -0.02190384, -0.01841735, ..., -0.02601784,\n",
       "         0.00966829, -0.00208664],\n",
       "       ...,\n",
       "       [-0.0129087 , -0.00222335,  0.02354596, ...,  0.01295494,\n",
       "         0.00692917,  0.00715465],\n",
       "       [ 0.01750363, -0.0083064 ,  0.00989071, ...,  0.01260056,\n",
       "         0.01552843, -0.00333524],\n",
       "       [-0.01494274, -0.00983312, -0.01817081, ..., -0.00294322,\n",
       "         0.0044816 , -0.01783037]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
